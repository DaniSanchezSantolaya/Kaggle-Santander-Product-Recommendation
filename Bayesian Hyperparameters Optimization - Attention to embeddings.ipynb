{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import dataset\n",
    "import pickle\n",
    "from dataset import DataSet\n",
    "import os\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters to optimize:\n",
    "- Number of hidden Neurons\n",
    "- Init stdev\n",
    "- Learning rate\n",
    "- optimizer\n",
    "- rnn_type\n",
    "- batch_size\n",
    "- embedding_size\n",
    "- dropout\n",
    "- l2\n",
    "- layer_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_model_base = 'BO_Attention_RNN_Adam_'\n",
    "num_model = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some auxilar functions\n",
    "def _seq_length(sequence):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence), reduction_indices=2))\n",
    "    length = tf.reduce_sum(used, reduction_indices=1)\n",
    "    length = tf.cast(length, tf.int32)\n",
    "    return length\n",
    "\n",
    "def _last_relevant(output, length):\n",
    "    batch_size = tf.shape(output)[0]\n",
    "    max_length = tf.shape(output)[1]\n",
    "    out_size = int(output.get_shape()[2])\n",
    "    index = tf.range(0, batch_size) * max_length + (length - 1)\n",
    "    flat = tf.reshape(output, [-1, out_size])\n",
    "    relevant = tf.gather(flat, index)\n",
    "\n",
    "    return relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(parameters):\n",
    "    \n",
    "    print(parameters)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    # Define placeholders\n",
    "    x = tf.placeholder(\"float\", [None, parameters['seq_length'], parameters['n_input']], name='x')\n",
    "    y = tf.placeholder(\"float\", [None, parameters['n_output']], name='y')\n",
    "    dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "    # Define weights and bias - For now we will try with attention to hidden state \n",
    "    weights = {\n",
    "        'alphas': tf.Variable(tf.random_normal([parameters['n_hidden'], 1], stddev=parameters['init_stdev']), name='w_alphas'),\n",
    "        'out': tf.Variable(tf.random_normal([parameters['embedding_size'], parameters['n_output']], stddev=parameters['init_stdev']), name='w_out'),\n",
    "        'emb': tf.Variable(tf.random_normal([parameters['n_input'], parameters['embedding_size']], stddev=parameters['init_stdev']), name='w_emb')\n",
    "    }\n",
    "\n",
    "    biases = {\n",
    "        'out': tf.Variable(tf.random_normal([parameters['n_output']]), name='b_out'),\n",
    "        'alphas': tf.Variable(tf.random_normal([1]), name='b_alphas'),\n",
    "        'emb': tf.Variable(tf.random_normal([parameters['embedding_size']]), name='b_emb')\n",
    "    }\n",
    "\n",
    "    # Compute embeddings\n",
    "    x_reshaped = tf.reshape(x, [-1, int(x.get_shape()[2])])\n",
    "    if parameters['embedding_activation'] == 'linear':\n",
    "        v = tf.matmul(x_reshaped, weights['emb'])\n",
    "    elif parameters['embedding_activation'] == 'tanh':\n",
    "        v = tf.tanh(tf.matmul(x_reshaped, weights['emb']) + biases['emb'])\n",
    "    elif parameters['embedding_activation'] == 'sigmoid':\n",
    "        v = tf.sigmoid(tf.matmul(x_reshaped, weights['emb']) + biases['emb'])\n",
    "    v_reshaped = tf.reshape(v, [-1, parameters['seq_length'], parameters['embedding_size']])\n",
    "    if parameters['layer_norm']:\n",
    "        v_reshaped = tf.contrib.layers.layer_norm(v_reshaped)\n",
    "\n",
    "    # Define RNN\n",
    "    if parameters['rnn_type'].lower() == 'lstm':\n",
    "        rnn_cell = tf.contrib.rnn.BasicLSTMCell(parameters['n_hidden'], forget_bias=1.0)\n",
    "    elif parameters['rnn_type'] == 'lstm2':\n",
    "        rnn_cell = tf.contrib.rnn.LSTMCell(parameters['n_hidden'])\n",
    "    elif parameters['rnn_type'].lower() == 'gru':\n",
    "        rnn_cell = tf.contrib.rnn.GRUCell(parameters['n_hidden'])\n",
    "    elif parameters['rnn_type'] == 'rnn':\n",
    "        rnn_cell = tf.contrib.rnn.BasicRNNCell(parameters['n_hidden'])\n",
    "    elif parameters['rnn_type'] == 'lstm_normalized':\n",
    "        rnn_cell = tf.contrib.rnn.LayerNormBasicLSTMCell(parameters['n_hidden'])\n",
    "    #Add dropout\n",
    "    if parameters['dropout'] > 0:\n",
    "        rnn_cell = tf.contrib.rnn.DropoutWrapper(rnn_cell, output_keep_prob=dropout_keep_prob)\n",
    "    outputs, states = tf.nn.dynamic_rnn(\n",
    "        rnn_cell,\n",
    "        v_reshaped,\n",
    "        dtype=tf.float32,\n",
    "        sequence_length=_seq_length(v_reshaped)\n",
    "    )\n",
    "\n",
    "\n",
    "    # Define attention weihts\n",
    "    outputs_reshaped = tf.reshape(outputs, [-1, int(outputs.get_shape()[2])])\n",
    "    ejs = tf.matmul(outputs_reshaped, weights['alphas']) + biases['alphas'] \n",
    "    ejs_reshaped = tf.reshape(ejs, [-1, int(outputs.get_shape()[1])])\n",
    "    alphas = tf.nn.softmax(ejs_reshaped, name='attention_weights') \n",
    "    reshaped_alphas = tf.reshape(alphas, [-1, 1])\n",
    "    # Define context\n",
    "    context = reshaped_alphas * v\n",
    "    context_reshaped = tf.reshape(context, [-1, parameters['seq_length'], int(context.get_shape()[1])])\n",
    "    context_reduced = tf.reduce_sum(context_reshaped, axis= 1)\n",
    "\n",
    "    # Normalize context by number of timesteps?\n",
    "    # Define logits and loss\n",
    "    logits = tf.matmul(context_reduced, weights['out']) + biases['out']\n",
    "    #pred_prob = tf.nn.softmax(logits, name=\"predictions\") # SIGMOID!!!!!!!!\n",
    "    pred_prob = tf.sigmoid(logits, name=\"predictions\")\n",
    "    #loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y)) SIGMOID!!!\n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "\n",
    "    # L2 regularization\n",
    "    for var in tf.trainable_variables():\n",
    "        if ('b_out' not in var.name) and ('b_alphas' not in var.name) and ('b_emb' not in var.name) and ('bias' not in var.name) and ('LayerNorm' not in var.name):\n",
    "            print('Variable ' + var.name + ' will be regularized')\n",
    "            loss += parameters['l2'] * tf.nn.l2_loss(var)\n",
    "\n",
    "\n",
    "    #Define optimizer\n",
    "    if parameters['optimizer'].lower() == 'sgd':\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=parameters['learning_rate']).minimize(loss)\n",
    "    elif parameters['optimizer'].lower() == 'adam':\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=parameters['learning_rate']).minimize(loss)\n",
    "    elif parameters['optimizer'].lower() == 'adadelta':\n",
    "        optimizer = tf.train.AdadeltaOptimizer(learning_rate=parameters['learning_rate']).minimize(loss)\n",
    "    elif parameters['optimizer'].lower() == 'adagrad':\n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate=parameters['learning_rate']).minimize(loss)\n",
    "\n",
    "    # Initialization\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    #Add summaries\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    # Create summaries to visualize weights\n",
    "    for var in tf.trainable_variables():\n",
    "        tf.summary.histogram(var.name, var)\n",
    "    # Summarize all gradients\n",
    "    grads = tf.gradients(loss, tf.trainable_variables())\n",
    "    grads = list(zip(grads, tf.trainable_variables()))\n",
    "    for grad, var in grads:\n",
    "        if grad is not None:\n",
    "            tf.summary.histogram(var.name + '/gradient', grad)\n",
    "            \n",
    "    return x,y,dropout_keep_prob,loss,init,optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    with open(\"preprocessed/dataset_augmented.pickle\", 'rb') as handle:\n",
    "        dataset = pickle.load(handle)\n",
    "    ds = DataSet(dataset)\n",
    "    del dataset\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(name_model, parameters, x, y, dropout_keep_prob, loss, init, optimizer, ds):\n",
    "    path_export_model = \"protobuf_models/\" + name_model + \"/\"\n",
    "    display_train_loss = 200\n",
    "    steps_periodic_checkpoint = 200\n",
    "    current_epoch = 0\n",
    "\n",
    "    # Start training\n",
    "    saver_last = tf.train.Saver()\n",
    "    saver_best = tf.train.Saver()\n",
    "    checkpoint_dir = './checkpoints/' + name_model + '/'\n",
    "    if not tf.gfile.Exists(checkpoint_dir):\n",
    "        tf.gfile.MakeDirs(checkpoint_dir)\n",
    "        tf.gfile.MakeDirs(checkpoint_dir + '/best_model')\n",
    "        tf.gfile.MakeDirs(checkpoint_dir + '/last_model')\n",
    "    best_loss = 150000000\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Create FileWriters for summaries\n",
    "        merged = tf.summary.merge_all()\n",
    "        train_writer = tf.summary.FileWriter('tensorboard/' + name_model + '/train', sess.graph)\n",
    "        val_writer = tf.summary.FileWriter('tensorboard/' + name_model + '/val', sess.graph)\n",
    "\n",
    "        # Run the initializer\n",
    "        sess.run(init)\n",
    "\n",
    "        step = 1\n",
    "        while ds.get_current_epoch('train') < parameters['num_epochs']:\n",
    "\n",
    "            # Get next batch\n",
    "            batch_x, batch_y = ds.next_batch(parameters['batch_size'])\n",
    "\n",
    "            # Run optimization op (backprop)\n",
    "            _ = sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, dropout_keep_prob: (1 - parameters['dropout'])})\n",
    "\n",
    "            # Compute train loss\n",
    "            if step % display_train_loss == 0 or step == 1:\n",
    "                # Calculate batch loss\n",
    "                train_loss, summary = sess.run([loss, merged], feed_dict={x: batch_x, y: batch_y, dropout_keep_prob: 1})\n",
    "                print(\"Step \" + str(step) + \", Train Loss: \" + str(train_loss))\n",
    "                train_writer.add_summary(summary, step * parameters['batch_size'])\n",
    "\n",
    "\n",
    "            # Periodic model checkpoint\n",
    "            if step % steps_periodic_checkpoint == 0:\n",
    "                checkpoint_dir_tmp = checkpoint_dir + '/last_model/'\n",
    "                checkpoint_path = os.path.join(checkpoint_dir_tmp, 'model_last.ckpt')\n",
    "                saver_last.save(sess, checkpoint_path, global_step=step*parameters['batch_size'])\n",
    "\n",
    "            # Compute val loss and save model at the end of each epoch\n",
    "            if ds.get_current_epoch('train') != current_epoch:\n",
    "                current_epoch = ds.get_current_epoch('train')\n",
    "                X_val, Y_val = ds.get_set('val')\n",
    "                val_loss, summary = sess.run([loss, merged], feed_dict={x: batch_x, y: batch_y, dropout_keep_prob: 1})\n",
    "                print(\"----End epoch \" + str(current_epoch - 1) + \", Val Loss: \" + str(val_loss))\n",
    "                val_writer.add_summary(summary, step * parameters['batch_size'])\n",
    "\n",
    "                # Check if validation loss is better\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    checkpoint_dir_tmp = checkpoint_dir + '/best_model/'\n",
    "                    checkpoint_path = os.path.join(checkpoint_dir_tmp, 'model_best.ckpt')\n",
    "                    saver_best.save(sess, checkpoint_path, global_step=step*parameters['batch_size'])\n",
    "\n",
    "\n",
    "                # Saved Model Builder \n",
    "                export_path = path_export_model + \"epoch\" + str(current_epoch - 1)\n",
    "                builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "                builder.add_meta_graph_and_variables(\n",
    "                      sess, [tf.saved_model.tag_constants.SERVING])\n",
    "                builder.save()\n",
    "                \n",
    "                if (current_epoch > 1) and (val_loss > 2):\n",
    "                    return -best_loss\n",
    "                if (current_epoch > 3) and (val_loss > 0.4):\n",
    "                    return -best_loss\n",
    "                if (current_epoch > 6) and (val_loss > 0.2):\n",
    "                    return -best_loss\n",
    "                if (current_epoch > 8) and (val_loss > 0.10):\n",
    "                    return -best_loss\n",
    "                if (current_epoch > 10) and (val_loss > 0.08):\n",
    "                    return -best_loss\n",
    "                if (current_epoch > 12) and (val_loss > 0.06):\n",
    "                    return -best_loss\n",
    "                if (current_epoch > 14) and (val_loss > 0.04):\n",
    "                    return -best_loss\n",
    "                if (current_epoch > 16) and (val_loss > 0.03):\n",
    "                    return -best_loss\n",
    "\n",
    "            step += 1\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "    return -best_loss\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_evaluate(n_hidden,\n",
    "                 init_stdev,\n",
    "                 learning_rate,\n",
    "                 optimizer,\n",
    "                 rnn_type,\n",
    "                 batch_size,\n",
    "                  embedding_size,\n",
    "                  dropout,\n",
    "                  l2,\n",
    "                  layer_norm):\n",
    "\n",
    "    global num_model\n",
    "    name_model = name_model_base + str(num_model)\n",
    "    num_model += 1\n",
    "    \n",
    "    parameters = {}\n",
    "    parameters['seq_length'] = 18\n",
    "    parameters['n_input'] = 48\n",
    "    parameters['n_output'] = 24\n",
    "    parameters['n_hidden'] = int(n_hidden)\n",
    "    parameters['init_stdev'] = init_stdev\n",
    "    parameters['learning_rate'] = learning_rate\n",
    "    parameters['optimizer'] = 'adam' #optimizer\n",
    "    parameters['rnn_type'] = 'lstm2'#rnn_type\n",
    "    parameters['num_epochs'] = 20\n",
    "    parameters['batch_size'] = int(batch_size)\n",
    "    parameters['embedding_size'] = int(embedding_size)\n",
    "    parameters['embedding_activation'] = 'linear'\n",
    "    parameters['dropout'] = dropout\n",
    "    parameters['l2'] = l2\n",
    "    parameters['layer_norm'] = False#layer_norm # Seems to work with 0.001 L2\n",
    "    \n",
    "    \n",
    "    x,y,dropout_keep_prob,loss,init,optimizer = create_model(parameters)\n",
    "    ds = load_dataset()\n",
    "    best_loss = train_model(name_model, parameters, x, y, dropout_keep_prob, loss, init, optimizer, ds)\n",
    "\n",
    "    return best_loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   batch_size |   dropout |   embedding_size |   init_stdev |        l2 |   layer_norm |   learning_rate |   n_hidden |   optimizer |   rnn_type | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.75837967036565068, 'optimizer': 'adam', 'batch_size': 54, 'dropout': 0.46036045735240427, 'init_stdev': 0.53764626449830077, 'num_epochs': 20, 'n_hidden': 179, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.079842876049038308, 'embedding_size': 45}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 3335.14\n",
      "Step 200, Train Loss: 0.139631\n",
      "Step 400, Train Loss: 0.143442\n",
      "Step 600, Train Loss: 0.147094\n",
      "Step 800, Train Loss: 0.135028\n",
      "Step 1000, Train Loss: 0.151811\n",
      "Step 1200, Train Loss: 0.155459\n",
      "Step 1400, Train Loss: 0.165118\n",
      "Step 1600, Train Loss: 0.158108\n",
      "Step 1800, Train Loss: 0.278435\n",
      "Step 2000, Train Loss: 6.83397\n",
      "Step 2200, Train Loss: 0.765861\n",
      "Step 2400, Train Loss: 3.64485\n",
      "Step 2600, Train Loss: 3.53569\n",
      "Step 2800, Train Loss: 2.63809\n",
      "Step 3000, Train Loss: 3.42466\n",
      "Step 3200, Train Loss: 3.20244\n",
      "Step 3400, Train Loss: 3.10237\n",
      "Step 3600, Train Loss: 3.06704\n",
      "Step 3800, Train Loss: 3.22012\n",
      "Step 4000, Train Loss: 3.08099\n",
      "Step 4200, Train Loss: 3.1923\n",
      "Step 4400, Train Loss: 3.15322\n",
      "----End epoch 0, Val Loss: 3.08309\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_0/epoch0\\\\saved_model.pb'\n",
      "Step 4600, Train Loss: 3.19585\n",
      "Step 4800, Train Loss: 3.1507\n",
      "Step 5000, Train Loss: 3.18241\n",
      "Step 5200, Train Loss: 3.16389\n",
      "Step 5400, Train Loss: 3.0959\n",
      "Step 5600, Train Loss: 3.21102\n",
      "Step 5800, Train Loss: 3.08527\n",
      "Step 6000, Train Loss: 3.0208\n",
      "Step 6200, Train Loss: 3.16331\n",
      "Step 6400, Train Loss: 3.09002\n",
      "Step 6600, Train Loss: 3.09053\n",
      "Step 6800, Train Loss: 3.13933\n",
      "Step 7000, Train Loss: 3.1639\n",
      "Step 7200, Train Loss: 3.14537\n",
      "Step 7400, Train Loss: 3.13358\n",
      "Step 7600, Train Loss: 3.04791\n",
      "Step 7800, Train Loss: 3.07271\n",
      "Step 8000, Train Loss: 3.07058\n",
      "Step 8200, Train Loss: 3.219\n",
      "Step 8400, Train Loss: 3.18609\n",
      "Step 8600, Train Loss: 3.19759\n",
      "Step 8800, Train Loss: 3.00575\n",
      "Step 9000, Train Loss: 3.13903\n",
      "----End epoch 1, Val Loss: 3.09524\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_0/epoch1\\\\saved_model.pb'\n",
      "    1 | 16m45s | \u001b[35m  -3.08309\u001b[0m | \u001b[32m     54.7716\u001b[0m | \u001b[32m   0.4604\u001b[0m | \u001b[32m         45.3881\u001b[0m | \u001b[32m      0.5376\u001b[0m | \u001b[32m   0.0798\u001b[0m | \u001b[32m      0.6709\u001b[0m | \u001b[32m         0.7584\u001b[0m | \u001b[32m  179.3354\u001b[0m | \u001b[32m     0.4519\u001b[0m | \u001b[32m    0.8469\u001b[0m | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.99135583827414508, 'optimizer': 'adam', 'batch_size': 101, 'dropout': 0.43414673473225951, 'init_stdev': 0.23841800055350373, 'num_epochs': 20, 'n_hidden': 43, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.087991120070499404, 'embedding_size': 39}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 603.654\n",
      "Step 200, Train Loss: 0.13611\n",
      "Step 400, Train Loss: 0.133976\n",
      "Step 600, Train Loss: 0.14541\n",
      "Step 800, Train Loss: 0.144913\n",
      "Step 1000, Train Loss: 0.143199\n",
      "Step 1200, Train Loss: 0.14828\n",
      "Step 1400, Train Loss: 0.1553\n",
      "Step 1600, Train Loss: 0.171977\n",
      "Step 1800, Train Loss: 1.01829\n",
      "Step 2000, Train Loss: 1.10337\n",
      "Step 2200, Train Loss: 0.29846\n",
      "Step 2400, Train Loss: 0.613139\n",
      "----End epoch 0, Val Loss: 0.609512\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_1/epoch0\\\\saved_model.pb'\n",
      "Step 2600, Train Loss: 0.954418\n",
      "Step 2800, Train Loss: 0.711114\n",
      "Step 3000, Train Loss: 0.626898\n",
      "Step 3200, Train Loss: 0.770163\n",
      "Step 3400, Train Loss: 0.80838\n",
      "Step 3600, Train Loss: 0.689638\n",
      "Step 3800, Train Loss: 0.744187\n",
      "Step 4000, Train Loss: 0.748652\n",
      "Step 4200, Train Loss: 0.677689\n",
      "Step 4400, Train Loss: 0.707544\n",
      "Step 4600, Train Loss: 0.687605\n",
      "Step 4800, Train Loss: 0.639603\n",
      "----End epoch 1, Val Loss: 0.798685\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_1/epoch1\\\\saved_model.pb'\n",
      "Step 5000, Train Loss: 0.677102\n",
      "Step 5200, Train Loss: 0.723325\n",
      "Step 5400, Train Loss: 0.713997\n",
      "Step 5600, Train Loss: 0.700437\n",
      "Step 5800, Train Loss: 0.698884\n",
      "Step 6000, Train Loss: 0.666746\n",
      "Step 6200, Train Loss: 0.754877\n",
      "Step 6400, Train Loss: 0.712203\n",
      "Step 6600, Train Loss: 0.693864\n",
      "Step 6800, Train Loss: 0.699225\n",
      "Step 7000, Train Loss: 0.703606\n",
      "Step 7200, Train Loss: 0.715636\n",
      "----End epoch 2, Val Loss: 0.755838\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_1/epoch2\\\\saved_model.pb'\n",
      "Step 7400, Train Loss: 0.742509\n",
      "Step 7600, Train Loss: 0.710205\n",
      "Step 7800, Train Loss: 0.758422\n",
      "Step 8000, Train Loss: 0.704713\n",
      "Step 8200, Train Loss: 0.750735\n",
      "Step 8400, Train Loss: 0.68746\n",
      "Step 8600, Train Loss: 0.698938\n",
      "Step 8800, Train Loss: 0.749479\n",
      "Step 9000, Train Loss: 0.681918\n",
      "Step 9200, Train Loss: 0.705086\n",
      "Step 9400, Train Loss: 0.717206\n",
      "Step 9600, Train Loss: 0.697811\n",
      "----End epoch 3, Val Loss: 0.727983\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_1/epoch3\\\\saved_model.pb'\n",
      "    2 | 11m01s | \u001b[35m  -0.60951\u001b[0m | \u001b[32m    101.7665\u001b[0m | \u001b[32m   0.4341\u001b[0m | \u001b[32m         39.0052\u001b[0m | \u001b[32m      0.2384\u001b[0m | \u001b[32m   0.0880\u001b[0m | \u001b[32m      0.7061\u001b[0m | \u001b[32m         0.9914\u001b[0m | \u001b[32m   43.2724\u001b[0m | \u001b[32m     0.7811\u001b[0m | \u001b[32m    0.0178\u001b[0m | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.15097116994119836, 'optimizer': 'adam', 'batch_size': 53, 'dropout': 0.26239322653520386, 'init_stdev': 0.77313466804220032, 'num_epochs': 20, 'n_hidden': 47, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.095754577522324399, 'embedding_size': 103}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 170.442\n",
      "Step 200, Train Loss: 0.144799\n",
      "Step 400, Train Loss: 0.142538\n",
      "Step 600, Train Loss: 0.151524\n",
      "Step 800, Train Loss: 0.152527\n",
      "Step 1000, Train Loss: 0.135634\n",
      "Step 1200, Train Loss: 0.147841\n",
      "Step 1400, Train Loss: 0.164986\n",
      "Step 1600, Train Loss: 0.159704\n",
      "Step 1800, Train Loss: 0.165576\n",
      "Step 2000, Train Loss: 0.166376\n",
      "Step 2200, Train Loss: 0.177725\n",
      "Step 2400, Train Loss: 0.160983\n",
      "Step 2600, Train Loss: 0.182886\n",
      "Step 2800, Train Loss: 0.172447\n",
      "Step 3000, Train Loss: 0.170087\n",
      "Step 3200, Train Loss: 0.155016\n",
      "Step 3400, Train Loss: 0.165389\n",
      "Step 3600, Train Loss: 0.162887\n",
      "Step 3800, Train Loss: 0.173701\n",
      "Step 4000, Train Loss: 0.173356\n",
      "Step 4200, Train Loss: 0.171762\n",
      "Step 4400, Train Loss: 0.177967\n",
      "Step 4600, Train Loss: 0.175385\n",
      "----End epoch 0, Val Loss: 0.166765\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_2/epoch0\\\\saved_model.pb'\n",
      "Step 4800, Train Loss: 0.171576\n",
      "Step 5000, Train Loss: 0.182144\n",
      "Step 5200, Train Loss: 0.176382\n",
      "Step 5400, Train Loss: 0.174701\n",
      "Step 5600, Train Loss: 0.165592\n",
      "Step 5800, Train Loss: 0.163068\n",
      "Step 6000, Train Loss: 0.158969\n",
      "Step 6200, Train Loss: 0.175631\n",
      "Step 6400, Train Loss: 0.176124\n",
      "Step 6600, Train Loss: 0.188532\n",
      "Step 6800, Train Loss: 0.184947\n",
      "Step 7000, Train Loss: 0.160815\n",
      "Step 7200, Train Loss: 0.166797\n",
      "Step 7400, Train Loss: 0.184847\n",
      "Step 7600, Train Loss: 0.18579\n",
      "Step 7800, Train Loss: 0.151176\n",
      "Step 8000, Train Loss: 0.188665\n",
      "Step 8200, Train Loss: 0.176941\n",
      "Step 8400, Train Loss: 0.173228\n",
      "Step 8600, Train Loss: 0.172606\n",
      "Step 8800, Train Loss: 0.170399\n",
      "Step 9000, Train Loss: 0.179426\n",
      "Step 9200, Train Loss: 0.176428\n",
      "----End epoch 1, Val Loss: 0.173896\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_2/epoch1\\\\saved_model.pb'\n",
      "Step 9400, Train Loss: 0.172335\n",
      "Step 9600, Train Loss: 0.160859\n",
      "Step 9800, Train Loss: 0.172433\n",
      "Step 10000, Train Loss: 0.168224\n",
      "Step 10200, Train Loss: 0.175525\n",
      "Step 10400, Train Loss: 0.172637\n",
      "Step 10600, Train Loss: 0.175493\n",
      "Step 10800, Train Loss: 0.16621\n",
      "Step 11000, Train Loss: 0.164385\n",
      "Step 11200, Train Loss: 0.171905\n",
      "Step 11400, Train Loss: 0.167696\n",
      "Step 11600, Train Loss: 0.169333\n",
      "Step 11800, Train Loss: 0.18816\n",
      "Step 12000, Train Loss: 0.178967\n",
      "Step 12200, Train Loss: 0.162867\n",
      "Step 12400, Train Loss: 0.184894\n",
      "Step 12600, Train Loss: 0.198231\n",
      "Step 12800, Train Loss: 0.178189\n",
      "Step 13000, Train Loss: 0.171975\n",
      "Step 13200, Train Loss: 0.185039\n",
      "Step 13400, Train Loss: 0.168704\n",
      "Step 13600, Train Loss: 0.183358\n",
      "Step 13800, Train Loss: 0.185045\n",
      "----End epoch 2, Val Loss: 0.163549\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_2/epoch2\\\\saved_model.pb'\n",
      "Step 14000, Train Loss: 0.16595\n",
      "Step 14200, Train Loss: 0.173668\n",
      "Step 14400, Train Loss: 0.170997\n",
      "Step 14600, Train Loss: 0.169737\n",
      "Step 14800, Train Loss: 0.173625\n",
      "Step 15000, Train Loss: 0.170485\n",
      "Step 15200, Train Loss: 0.171898\n",
      "Step 15400, Train Loss: 0.180046\n",
      "Step 15600, Train Loss: 0.169183\n",
      "Step 15800, Train Loss: 0.176298\n",
      "Step 16000, Train Loss: 0.185389\n",
      "Step 16200, Train Loss: 0.16627\n",
      "Step 16400, Train Loss: 0.17289\n",
      "Step 16600, Train Loss: 0.165764\n",
      "Step 16800, Train Loss: 0.175074\n",
      "Step 17000, Train Loss: 0.173181\n",
      "Step 17200, Train Loss: 0.17109\n",
      "Step 17400, Train Loss: 0.1794\n",
      "Step 17600, Train Loss: 0.160938\n",
      "Step 17800, Train Loss: 0.171893\n",
      "Step 18000, Train Loss: 0.183779\n",
      "Step 18200, Train Loss: 0.167803\n",
      "Step 18400, Train Loss: 0.176458\n",
      "----End epoch 3, Val Loss: 0.178389\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_2/epoch3\\\\saved_model.pb'\n",
      "Step 18600, Train Loss: 0.176058\n",
      "Step 18800, Train Loss: 0.175268\n",
      "Step 19000, Train Loss: 0.166432\n",
      "Step 19200, Train Loss: 0.173475\n",
      "Step 19400, Train Loss: 0.170272\n",
      "Step 19600, Train Loss: 0.183268\n",
      "Step 19800, Train Loss: 0.170339\n",
      "Step 20000, Train Loss: 0.154161\n",
      "Step 20200, Train Loss: 0.17192\n",
      "Step 20400, Train Loss: 0.171125\n",
      "Step 20600, Train Loss: 0.177634\n",
      "Step 20800, Train Loss: 0.161402\n",
      "Step 21000, Train Loss: 0.167106\n",
      "Step 21200, Train Loss: 0.16454\n",
      "Step 21400, Train Loss: 0.167305\n",
      "Step 21600, Train Loss: 0.175433\n",
      "Step 21800, Train Loss: 0.171242\n",
      "Step 22000, Train Loss: 0.170005\n",
      "Step 22200, Train Loss: 0.181356\n",
      "Step 22400, Train Loss: 0.150859\n",
      "Step 22600, Train Loss: 0.174955\n",
      "Step 22800, Train Loss: 0.184131\n",
      "Step 23000, Train Loss: 0.170581\n",
      "----End epoch 4, Val Loss: 0.179198\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_2/epoch4\\\\saved_model.pb'\n",
      "Step 23200, Train Loss: 0.169903\n",
      "Step 23400, Train Loss: 0.174099\n",
      "Step 23600, Train Loss: 0.178687\n",
      "Step 23800, Train Loss: 0.177958\n",
      "Step 24000, Train Loss: 0.171326\n",
      "Step 24200, Train Loss: 0.181286\n",
      "Step 24400, Train Loss: 0.168261\n",
      "Step 24600, Train Loss: 0.157197\n",
      "Step 24800, Train Loss: 0.183508\n",
      "Step 25000, Train Loss: 0.154619\n",
      "Step 25200, Train Loss: 0.17131\n",
      "Step 25400, Train Loss: 0.174162\n",
      "Step 25600, Train Loss: 0.188381\n",
      "Step 25800, Train Loss: 0.175865\n",
      "Step 26000, Train Loss: 0.177358\n",
      "Step 26200, Train Loss: 0.178195\n",
      "Step 26400, Train Loss: 0.178557\n",
      "Step 26600, Train Loss: 0.164616\n",
      "Step 26800, Train Loss: 0.169684\n",
      "Step 27000, Train Loss: 0.188923\n",
      "Step 27200, Train Loss: 0.174066\n",
      "Step 27400, Train Loss: 0.162186\n",
      "Step 27600, Train Loss: 0.170464\n",
      "----End epoch 5, Val Loss: 0.160118\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_2/epoch5\\\\saved_model.pb'\n",
      "Step 27800, Train Loss: 0.177765\n",
      "Step 28000, Train Loss: 0.165138\n",
      "Step 28200, Train Loss: 0.160167\n",
      "Step 28400, Train Loss: 0.162852\n",
      "Step 28600, Train Loss: 0.171499\n",
      "Step 28800, Train Loss: 0.163853\n",
      "Step 29000, Train Loss: 0.16837\n",
      "Step 29200, Train Loss: 0.159678\n",
      "Step 29400, Train Loss: 0.178883\n",
      "Step 29600, Train Loss: 0.179075\n",
      "Step 29800, Train Loss: 0.177531\n",
      "Step 30000, Train Loss: 0.16182\n",
      "Step 30200, Train Loss: 0.17279\n",
      "Step 30400, Train Loss: 0.167943\n",
      "Step 30600, Train Loss: 0.168843\n",
      "Step 30800, Train Loss: 0.163296\n",
      "Step 31000, Train Loss: 0.169391\n",
      "Step 31200, Train Loss: 0.183433\n",
      "Step 31400, Train Loss: 0.165131\n",
      "Step 31600, Train Loss: 0.175116\n",
      "Step 31800, Train Loss: 0.17256\n",
      "Step 32000, Train Loss: 0.173923\n",
      "Step 32200, Train Loss: 0.178339\n",
      "----End epoch 6, Val Loss: 0.185135\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_2/epoch6\\\\saved_model.pb'\n",
      "Step 32400, Train Loss: 0.156651\n",
      "Step 32600, Train Loss: 0.158469\n",
      "Step 32800, Train Loss: 0.168966\n",
      "Step 33000, Train Loss: 0.162414\n",
      "Step 33200, Train Loss: 0.180029\n",
      "Step 33400, Train Loss: 0.167379\n",
      "Step 33600, Train Loss: 0.179589\n",
      "Step 33800, Train Loss: 0.165623\n",
      "Step 34000, Train Loss: 0.16337\n",
      "Step 34200, Train Loss: 0.169484\n",
      "Step 34400, Train Loss: 0.171401\n",
      "Step 34600, Train Loss: 0.177538\n",
      "Step 34800, Train Loss: 0.172689\n",
      "Step 35000, Train Loss: 0.177274\n",
      "Step 35200, Train Loss: 0.171832\n",
      "Step 35400, Train Loss: 0.173135\n",
      "Step 35600, Train Loss: 0.18067\n",
      "Step 35800, Train Loss: 0.167223\n",
      "Step 36000, Train Loss: 0.176207\n",
      "Step 36200, Train Loss: 0.181444\n",
      "Step 36400, Train Loss: 0.17378\n",
      "Step 36600, Train Loss: 0.166014\n",
      "Step 36800, Train Loss: 0.158313\n",
      "----End epoch 7, Val Loss: 0.169685\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_2/epoch7\\\\saved_model.pb'\n",
      "Step 37000, Train Loss: 0.181314\n",
      "Step 37200, Train Loss: 0.169819\n",
      "Step 37400, Train Loss: 0.163086\n",
      "Step 37600, Train Loss: 0.177909\n",
      "Step 37800, Train Loss: 0.161344\n",
      "Step 38000, Train Loss: 0.163404\n",
      "Step 38200, Train Loss: 0.172963\n",
      "Step 38400, Train Loss: 0.184137\n",
      "Step 38600, Train Loss: 0.162331\n",
      "Step 38800, Train Loss: 0.179877\n",
      "Step 39000, Train Loss: 0.168427\n",
      "Step 39200, Train Loss: 0.165326\n",
      "Step 39400, Train Loss: 0.180262\n",
      "Step 39600, Train Loss: 0.167583\n",
      "Step 39800, Train Loss: 0.162203\n",
      "Step 40000, Train Loss: 0.16287\n",
      "Step 40200, Train Loss: 0.175562\n",
      "Step 40400, Train Loss: 0.174078\n",
      "Step 40600, Train Loss: 0.178064\n",
      "Step 40800, Train Loss: 0.182483\n",
      "Step 41000, Train Loss: 0.168816\n",
      "Step 41200, Train Loss: 0.169558\n",
      "Step 41400, Train Loss: 0.169678\n",
      "----End epoch 8, Val Loss: 0.165347\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_2/epoch8\\\\saved_model.pb'\n",
      "    3 | 37m25s | \u001b[35m  -0.16012\u001b[0m | \u001b[32m     53.6451\u001b[0m | \u001b[32m   0.2624\u001b[0m | \u001b[32m        103.2118\u001b[0m | \u001b[32m      0.7731\u001b[0m | \u001b[32m   0.0958\u001b[0m | \u001b[32m      0.9028\u001b[0m | \u001b[32m         0.1510\u001b[0m | \u001b[32m   47.6670\u001b[0m | \u001b[32m     0.4947\u001b[0m | \u001b[32m    0.9836\u001b[0m | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.1835797650079635, 'optimizer': 'adam', 'batch_size': 253, 'dropout': 0.023117539348304184, 'init_stdev': 0.94637410377023723, 'num_epochs': 20, 'n_hidden': 199, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.015682619089400718, 'embedding_size': 74}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 75.1222\n",
      "Step 200, Train Loss: 0.141071\n",
      "Step 400, Train Loss: 0.148479\n",
      "Step 600, Train Loss: 0.143451\n",
      "Step 800, Train Loss: 0.14383\n",
      "----End epoch 0, Val Loss: 0.146026\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_3/epoch0\\\\saved_model.pb'\n",
      "Step 1000, Train Loss: 0.136864\n",
      "Step 1200, Train Loss: 0.143023\n",
      "Step 1400, Train Loss: 0.169179\n",
      "Step 1600, Train Loss: 0.172249\n",
      "Step 1800, Train Loss: 0.173255\n",
      "----End epoch 1, Val Loss: 0.185712\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_3/epoch1\\\\saved_model.pb'\n",
      "Step 2000, Train Loss: 0.174747\n",
      "Step 2200, Train Loss: 0.18536\n",
      "Step 2400, Train Loss: 0.183304\n",
      "Step 2600, Train Loss: 0.192011\n",
      "Step 2800, Train Loss: 0.168257\n",
      "----End epoch 2, Val Loss: 0.170783\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_3/epoch2\\\\saved_model.pb'\n",
      "Step 3000, Train Loss: 0.183597\n",
      "Step 3200, Train Loss: 0.187827\n",
      "Step 3400, Train Loss: 0.171267\n",
      "Step 3600, Train Loss: 0.201495\n",
      "Step 3800, Train Loss: 0.177211\n",
      "----End epoch 3, Val Loss: 0.180854\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_3/epoch3\\\\saved_model.pb'\n",
      "Step 4000, Train Loss: 0.188146\n",
      "Step 4200, Train Loss: 0.181115\n",
      "Step 4400, Train Loss: 0.180571\n",
      "Step 4600, Train Loss: 0.187535\n",
      "Step 4800, Train Loss: 0.178296\n",
      "----End epoch 4, Val Loss: 0.183419\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_3/epoch4\\\\saved_model.pb'\n",
      "Step 5000, Train Loss: 0.179957\n",
      "Step 5200, Train Loss: 0.184682\n",
      "Step 5400, Train Loss: 0.186855\n",
      "Step 5600, Train Loss: 0.185931\n",
      "----End epoch 5, Val Loss: 0.190934\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_3/epoch5\\\\saved_model.pb'\n",
      "Step 5800, Train Loss: 0.187799\n",
      "Step 6000, Train Loss: 0.176338\n",
      "Step 6200, Train Loss: 0.183706\n",
      "Step 6400, Train Loss: 0.191955\n",
      "Step 6600, Train Loss: 0.191178\n",
      "----End epoch 6, Val Loss: 0.18608\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_3/epoch6\\\\saved_model.pb'\n",
      "Step 6800, Train Loss: 0.180983\n",
      "Step 7000, Train Loss: 0.182906\n",
      "Step 7200, Train Loss: 0.192074\n",
      "Step 7400, Train Loss: 0.180443\n",
      "Step 7600, Train Loss: 0.180581\n",
      "----End epoch 7, Val Loss: 0.179542\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_3/epoch7\\\\saved_model.pb'\n",
      "Step 7800, Train Loss: 0.197646\n",
      "Step 8000, Train Loss: 0.185407\n",
      "Step 8200, Train Loss: 0.196048\n",
      "Step 8400, Train Loss: 0.179015\n",
      "Step 8600, Train Loss: 0.185482\n",
      "----End epoch 8, Val Loss: 0.189831\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_3/epoch8\\\\saved_model.pb'\n",
      "    4 | 66m06s | \u001b[35m  -0.14603\u001b[0m | \u001b[32m    253.3146\u001b[0m | \u001b[32m   0.0231\u001b[0m | \u001b[32m         74.6330\u001b[0m | \u001b[32m      0.9464\u001b[0m | \u001b[32m   0.0157\u001b[0m | \u001b[32m      0.3473\u001b[0m | \u001b[32m         0.1836\u001b[0m | \u001b[32m  199.0376\u001b[0m | \u001b[32m     0.7595\u001b[0m | \u001b[32m    0.0538\u001b[0m | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.28610533725371184, 'optimizer': 'adam', 'batch_size': 175, 'dropout': 0.65912785754020076, 'init_stdev': 0.34726133779843205, 'num_epochs': 20, 'n_hidden': 76, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.0026949024039536699, 'embedding_size': 56}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 3.70292\n",
      "Step 200, Train Loss: 0.145973\n",
      "Step 400, Train Loss: 0.127175\n",
      "Step 600, Train Loss: 0.130569\n",
      "Step 800, Train Loss: 0.143156\n",
      "Step 1000, Train Loss: 0.138596\n",
      "Step 1200, Train Loss: 0.136867\n",
      "----End epoch 0, Val Loss: 0.150908\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_4/epoch0\\\\saved_model.pb'\n",
      "Step 1400, Train Loss: 0.142378\n",
      "Step 1600, Train Loss: 0.144414\n",
      "Step 1800, Train Loss: 0.148837\n",
      "Step 2000, Train Loss: 0.139412\n",
      "Step 2200, Train Loss: 0.145835\n",
      "Step 2400, Train Loss: 0.13423\n",
      "Step 2600, Train Loss: 0.1619\n",
      "----End epoch 1, Val Loss: 0.15353\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_4/epoch1\\\\saved_model.pb'\n",
      "Step 2800, Train Loss: 0.142009\n",
      "Step 3000, Train Loss: 0.137676\n",
      "Step 3200, Train Loss: 0.134082\n",
      "Step 3400, Train Loss: 0.141092\n",
      "Step 3600, Train Loss: 0.151638\n",
      "Step 3800, Train Loss: 0.148085\n",
      "Step 4000, Train Loss: 0.138308\n",
      "----End epoch 2, Val Loss: 0.141018\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_4/epoch2\\\\saved_model.pb'\n",
      "Step 4200, Train Loss: 0.136999\n",
      "Step 4400, Train Loss: 0.154899\n",
      "Step 4600, Train Loss: 0.139295\n",
      "Step 4800, Train Loss: 0.148592\n",
      "Step 5000, Train Loss: 0.13805\n",
      "Step 5200, Train Loss: 0.139673\n",
      "Step 5400, Train Loss: 0.136368\n",
      "----End epoch 3, Val Loss: 0.151758\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_4/epoch3\\\\saved_model.pb'\n",
      "Step 5600, Train Loss: 0.146232\n",
      "Step 5800, Train Loss: 0.144752\n",
      "Step 6000, Train Loss: 0.150031\n",
      "Step 6200, Train Loss: 0.139391\n",
      "Step 6400, Train Loss: 0.140882\n",
      "Step 6600, Train Loss: 0.143143\n",
      "Step 6800, Train Loss: 0.142461\n",
      "----End epoch 4, Val Loss: 0.14223\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_4/epoch4\\\\saved_model.pb'\n",
      "Step 7000, Train Loss: 0.141253\n",
      "Step 7200, Train Loss: 0.143298\n",
      "Step 7400, Train Loss: 0.147434\n",
      "Step 7600, Train Loss: 0.142859\n",
      "Step 7800, Train Loss: 0.151881\n",
      "Step 8000, Train Loss: 0.136637\n",
      "Step 8200, Train Loss: 0.144096\n",
      "----End epoch 5, Val Loss: 0.142761\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_4/epoch5\\\\saved_model.pb'\n",
      "Step 8400, Train Loss: 0.144015\n",
      "Step 8600, Train Loss: 0.144361\n",
      "Step 8800, Train Loss: 0.142152\n",
      "Step 9000, Train Loss: 0.144141\n",
      "Step 9200, Train Loss: 0.152547\n",
      "Step 9400, Train Loss: 0.138866\n",
      "Step 9600, Train Loss: 0.136663\n",
      "----End epoch 6, Val Loss: 0.13758\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_4/epoch6\\\\saved_model.pb'\n",
      "Step 9800, Train Loss: 0.147693\n",
      "Step 10000, Train Loss: 0.145504\n",
      "Step 10200, Train Loss: 0.1507\n",
      "Step 10400, Train Loss: 0.138028\n",
      "Step 10600, Train Loss: 0.148512\n",
      "Step 10800, Train Loss: 0.150699\n",
      "Step 11000, Train Loss: 0.142286\n",
      "----End epoch 7, Val Loss: 0.146762\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_4/epoch7\\\\saved_model.pb'\n",
      "Step 11200, Train Loss: 0.154138\n",
      "Step 11400, Train Loss: 0.143338\n",
      "Step 11600, Train Loss: 0.13452\n",
      "Step 11800, Train Loss: 0.140386\n",
      "Step 12000, Train Loss: 0.13985\n",
      "Step 12200, Train Loss: 0.135954\n",
      "Step 12400, Train Loss: 0.140377\n",
      "----End epoch 8, Val Loss: 0.143431\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_4/epoch8\\\\saved_model.pb'\n",
      "    5 | 31m40s | \u001b[35m  -0.13758\u001b[0m | \u001b[32m    175.0094\u001b[0m | \u001b[32m   0.6591\u001b[0m | \u001b[32m         56.1878\u001b[0m | \u001b[32m      0.3473\u001b[0m | \u001b[32m   0.0027\u001b[0m | \u001b[32m      0.8223\u001b[0m | \u001b[32m         0.2861\u001b[0m | \u001b[32m   76.8335\u001b[0m | \u001b[32m     0.9019\u001b[0m | \u001b[32m    0.2522\u001b[0m | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   batch_size |   dropout |   embedding_size |   init_stdev |        l2 |   layer_norm |   learning_rate |   n_hidden |   optimizer |   rnn_type | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.0001, 'optimizer': 'adam', 'batch_size': 256, 'dropout': 0.0, 'init_stdev': 1.0, 'num_epochs': 20, 'n_hidden': 25, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.0, 'embedding_size': 128}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 1.41343\n",
      "Step 200, Train Loss: 0.908252\n",
      "Step 400, Train Loss: 0.882111\n",
      "Step 600, Train Loss: 0.829047\n",
      "Step 800, Train Loss: 0.729933\n",
      "----End epoch 0, Val Loss: 0.631096\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_5/epoch0\\\\saved_model.pb'\n",
      "Step 1000, Train Loss: 0.589184\n",
      "Step 1200, Train Loss: 0.497042\n",
      "Step 1400, Train Loss: 0.468648\n",
      "Step 1600, Train Loss: 0.42799\n",
      "Step 1800, Train Loss: 0.355745\n",
      "----End epoch 1, Val Loss: 0.287593\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_5/epoch1\\\\saved_model.pb'\n",
      "Step 2000, Train Loss: 0.322666\n",
      "Step 2200, Train Loss: 0.304232\n",
      "Step 2400, Train Loss: 0.288205\n",
      "Step 2600, Train Loss: 0.257829\n",
      "Step 2800, Train Loss: 0.241806\n",
      "----End epoch 2, Val Loss: 0.25182\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_5/epoch2\\\\saved_model.pb'\n",
      "Step 3000, Train Loss: 0.233589\n",
      "Step 3200, Train Loss: 0.181738\n",
      "Step 3400, Train Loss: 0.188659\n",
      "Step 3600, Train Loss: 0.164197\n",
      "Step 3800, Train Loss: 0.132868\n",
      "----End epoch 3, Val Loss: 0.136441\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_5/epoch3\\\\saved_model.pb'\n",
      "Step 4000, Train Loss: 0.111847\n",
      "Step 4200, Train Loss: 0.126198\n",
      "Step 4400, Train Loss: 0.0992055\n",
      "Step 4600, Train Loss: 0.117882\n",
      "----End epoch 4, Val Loss: 0.103522\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_5/epoch4\\\\saved_model.pb'\n",
      "Step 4800, Train Loss: 0.103972\n",
      "Step 5000, Train Loss: 0.0939594\n",
      "Step 5200, Train Loss: 0.10095\n",
      "Step 5400, Train Loss: 0.0889821\n",
      "Step 5600, Train Loss: 0.102774\n",
      "----End epoch 5, Val Loss: 0.0946387\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_5/epoch5\\\\saved_model.pb'\n",
      "Step 5800, Train Loss: 0.109906\n",
      "Step 6000, Train Loss: 0.0896116\n",
      "Step 6200, Train Loss: 0.0923409\n",
      "Step 6400, Train Loss: 0.0966446\n",
      "Step 6600, Train Loss: 0.0827616\n",
      "----End epoch 6, Val Loss: 0.0950767\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_5/epoch6\\\\saved_model.pb'\n",
      "Step 6800, Train Loss: 0.0844822\n",
      "Step 7000, Train Loss: 0.0893774\n",
      "Step 7200, Train Loss: 0.0832825\n",
      "Step 7400, Train Loss: 0.0734461\n",
      "Step 7600, Train Loss: 0.0779307\n",
      "----End epoch 7, Val Loss: 0.0783711\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_5/epoch7\\\\saved_model.pb'\n",
      "Step 7800, Train Loss: 0.0860415\n",
      "Step 8000, Train Loss: 0.0967302\n",
      "Step 8200, Train Loss: 0.0709206\n",
      "Step 8400, Train Loss: 0.0700126\n",
      "----End epoch 8, Val Loss: 0.0876403\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_5/epoch8\\\\saved_model.pb'\n",
      "Step 8600, Train Loss: 0.0724651\n",
      "Step 8800, Train Loss: 0.0771693\n",
      "Step 9000, Train Loss: 0.0776718\n",
      "Step 9200, Train Loss: 0.0983959\n",
      "Step 9400, Train Loss: 0.0696903\n",
      "----End epoch 9, Val Loss: 0.0749488\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_5/epoch9\\\\saved_model.pb'\n",
      "Step 9600, Train Loss: 0.0778104\n",
      "Step 9800, Train Loss: 0.0771163\n",
      "Step 10000, Train Loss: 0.0846594\n",
      "Step 10200, Train Loss: 0.0703855\n",
      "Step 10400, Train Loss: 0.068505\n",
      "----End epoch 10, Val Loss: 0.0683698\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_5/epoch10\\\\saved_model.pb'\n",
      "Step 10600, Train Loss: 0.0589504\n",
      "Step 10800, Train Loss: 0.0702693\n",
      "Step 11000, Train Loss: 0.069698\n",
      "Step 11200, Train Loss: 0.0650526\n",
      "Step 11400, Train Loss: 0.0767489\n",
      "----End epoch 11, Val Loss: 0.0776597\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_5/epoch11\\\\saved_model.pb'\n",
      "Step 11600, Train Loss: 0.0798085\n",
      "Step 11800, Train Loss: 0.0764742\n",
      "Step 12000, Train Loss: 0.0678724\n",
      "Step 12200, Train Loss: 0.0731289\n",
      "Step 12400, Train Loss: 0.0700336\n",
      "----End epoch 12, Val Loss: 0.0765747\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_5/epoch12\\\\saved_model.pb'\n",
      "    6 | 31m39s | \u001b[35m  -0.06837\u001b[0m | \u001b[32m    256.0000\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m        128.0000\u001b[0m | \u001b[32m      1.0000\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m      0.0000\u001b[0m | \u001b[32m         0.0001\u001b[0m | \u001b[32m   25.0000\u001b[0m | \u001b[32m     0.0000\u001b[0m | \u001b[32m    1.0000\u001b[0m | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 1.0, 'optimizer': 'adam', 'batch_size': 256, 'dropout': 0.75, 'init_stdev': 0.0001, 'num_epochs': 20, 'n_hidden': 25, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.10000000000000001, 'embedding_size': 8}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 158.044\n",
      "Step 200, Train Loss: 0.140894\n",
      "Step 400, Train Loss: 0.142701\n",
      "Step 600, Train Loss: 0.140465\n",
      "Step 800, Train Loss: 0.137819\n",
      "----End epoch 0, Val Loss: 0.147145\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_6/epoch0\\\\saved_model.pb'\n",
      "Step 1000, Train Loss: 0.152983\n",
      "Step 1200, Train Loss: 0.140975\n",
      "Step 1400, Train Loss: 0.144114\n",
      "Step 1600, Train Loss: 0.145344\n",
      "Step 1800, Train Loss: 0.528356\n",
      "----End epoch 1, Val Loss: 0.39944\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_6/epoch1\\\\saved_model.pb'\n",
      "Step 2000, Train Loss: 0.411864\n",
      "Step 2200, Train Loss: 0.164917\n",
      "Step 2400, Train Loss: 0.215184\n",
      "Step 2600, Train Loss: 0.34695\n",
      "Step 2800, Train Loss: 0.400473\n",
      "----End epoch 2, Val Loss: 0.333648\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_6/epoch2\\\\saved_model.pb'\n",
      "Step 3000, Train Loss: 0.217689\n",
      "Step 3200, Train Loss: 0.277409\n",
      "Step 3400, Train Loss: 0.354126\n",
      "Step 3600, Train Loss: 0.345501\n",
      "Step 3800, Train Loss: 0.274918\n",
      "----End epoch 3, Val Loss: 0.298434\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_6/epoch3\\\\saved_model.pb'\n",
      "Step 4000, Train Loss: 0.291823\n",
      "Step 4200, Train Loss: 0.299839\n",
      "Step 4400, Train Loss: 0.287239\n",
      "Step 4600, Train Loss: 0.309374\n",
      "----End epoch 4, Val Loss: 0.30099\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_6/epoch4\\\\saved_model.pb'\n",
      "Step 4800, Train Loss: 0.298252\n",
      "Step 5000, Train Loss: 0.285893\n",
      "Step 5200, Train Loss: 0.283038\n",
      "Step 5400, Train Loss: 0.300757\n",
      "Step 5600, Train Loss: 0.295597\n",
      "----End epoch 5, Val Loss: 0.30649\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_6/epoch5\\\\saved_model.pb'\n",
      "Step 5800, Train Loss: 0.291918\n",
      "Step 6000, Train Loss: 0.311165\n",
      "Step 6200, Train Loss: 0.292792\n",
      "Step 6400, Train Loss: 0.291818\n",
      "Step 6600, Train Loss: 0.271952\n",
      "----End epoch 6, Val Loss: 0.29519\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_6/epoch6\\\\saved_model.pb'\n",
      "    7 | 11m27s |   -0.14714 |     256.0000 |    0.7500 |           8.0000 |       0.0001 |    0.1000 |       1.0000 |          1.0000 |    25.0000 |      0.0000 |     0.0000 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 1.0, 'optimizer': 'adam', 'batch_size': 145, 'dropout': 0.75, 'init_stdev': 0.0001, 'num_epochs': 20, 'n_hidden': 25, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.0, 'embedding_size': 128}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 0.511819\n",
      "Step 200, Train Loss: 0.138702\n",
      "Step 400, Train Loss: 0.143046\n",
      "Step 600, Train Loss: 0.151382\n",
      "Step 800, Train Loss: 0.155001\n",
      "Step 1000, Train Loss: 0.167497\n",
      "Step 1200, Train Loss: 0.155911\n",
      "Step 1400, Train Loss: 0.180691\n",
      "Step 1600, Train Loss: 0.148918\n",
      "----End epoch 0, Val Loss: 4.87444\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_7/epoch0\\\\saved_model.pb'\n",
      "Step 1800, Train Loss: 0.157775\n",
      "Step 2000, Train Loss: 0.13217\n",
      "Step 2200, Train Loss: 21.65\n",
      "Step 2400, Train Loss: 0.153924\n",
      "Step 2600, Train Loss: 0.15551\n",
      "Step 2800, Train Loss: 0.147895\n",
      "Step 3000, Train Loss: 0.1367\n",
      "Step 3200, Train Loss: 0.145738\n",
      "----End epoch 1, Val Loss: 0.158039\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_7/epoch1\\\\saved_model.pb'\n",
      "Step 3400, Train Loss: 0.157637\n",
      "Step 3600, Train Loss: 0.146565\n",
      "Step 3800, Train Loss: 0.159437\n",
      "Step 4000, Train Loss: 0.263698\n",
      "Step 4200, Train Loss: 0.155684\n",
      "Step 4400, Train Loss: 0.147576\n",
      "Step 4600, Train Loss: 0.161963\n",
      "Step 4800, Train Loss: 0.148344\n",
      "Step 5000, Train Loss: 0.948573\n",
      "----End epoch 2, Val Loss: 5.82196\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_7/epoch2\\\\saved_model.pb'\n",
      "    8 | 08m31s |   -0.15804 |     145.2780 |    0.7500 |         128.0000 |       0.0001 |    0.0000 |       1.0000 |          1.0000 |    25.0000 |      1.0000 |     0.0000 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 1.0, 'optimizer': 'adam', 'batch_size': 256, 'dropout': 0.75, 'init_stdev': 0.0001, 'num_epochs': 20, 'n_hidden': 250, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.10000000000000001, 'embedding_size': 8}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 12055.0\n",
      "Step 200, Train Loss: 0.142561\n",
      "Step 400, Train Loss: 0.142058\n",
      "Step 600, Train Loss: 0.14512\n",
      "Step 800, Train Loss: 0.144031\n",
      "----End epoch 0, Val Loss: 0.146756\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_8/epoch0\\\\saved_model.pb'\n",
      "Step 1000, Train Loss: 0.145041\n",
      "Step 1200, Train Loss: 0.17148\n",
      "Step 1400, Train Loss: 0.176034\n",
      "Step 1600, Train Loss: 0.214272\n",
      "Step 1800, Train Loss: 0.510158\n",
      "----End epoch 1, Val Loss: 2.76388\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_8/epoch1\\\\saved_model.pb'\n",
      "    9 | 16m48s |   -0.14676 |     256.0000 |    0.7500 |           8.0000 |       0.0001 |    0.1000 |       1.0000 |          1.0000 |   250.0000 |      0.0000 |     1.0000 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 1.0, 'optimizer': 'adam', 'batch_size': 256, 'dropout': 0.75, 'init_stdev': 0.0001, 'num_epochs': 20, 'n_hidden': 250, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.10000000000000001, 'embedding_size': 128}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 18063.1\n",
      "Step 200, Train Loss: 0.137773\n",
      "Step 400, Train Loss: 0.140959\n",
      "Step 600, Train Loss: 0.141501\n",
      "Step 800, Train Loss: 0.145571\n",
      "----End epoch 0, Val Loss: 0.18022\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_9/epoch0\\\\saved_model.pb'\n",
      "Step 1000, Train Loss: 0.172044\n",
      "Step 1200, Train Loss: 0.189699\n",
      "Step 1400, Train Loss: 0.378693\n",
      "Step 1600, Train Loss: 0.611922\n",
      "Step 1800, Train Loss: 2.05317\n",
      "----End epoch 1, Val Loss: 8.71834\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_9/epoch1\\\\saved_model.pb'\n",
      "   10 | 21m47s |   -0.18022 |     256.0000 |    0.7500 |         128.0000 |       0.0001 |    0.1000 |       0.0000 |          1.0000 |   250.0000 |      0.0000 |     1.0000 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 1.0, 'optimizer': 'adam', 'batch_size': 256, 'dropout': 0.75, 'init_stdev': 0.0001, 'num_epochs': 20, 'n_hidden': 120, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.10000000000000001, 'embedding_size': 128}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 5819.12\n",
      "Step 200, Train Loss: 0.145786\n",
      "Step 400, Train Loss: 0.144665\n",
      "Step 600, Train Loss: 0.145066\n",
      "Step 800, Train Loss: 0.140904\n",
      "----End epoch 0, Val Loss: 0.169514\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_10/epoch0\\\\saved_model.pb'\n",
      "Step 1000, Train Loss: 0.149644\n",
      "Step 1200, Train Loss: 0.15427\n",
      "Step 1400, Train Loss: 0.170263\n",
      "Step 1600, Train Loss: 0.178835\n",
      "Step 1800, Train Loss: 0.33235\n",
      "----End epoch 1, Val Loss: 10.4228\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_10/epoch1\\\\saved_model.pb'\n",
      "   11 | 10m47s |   -0.16951 |     256.0000 |    0.7500 |         128.0000 |       0.0001 |    0.1000 |       1.0000 |          1.0000 |   120.2820 |      1.0000 |     1.0000 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.0001, 'optimizer': 'adam', 'batch_size': 256, 'dropout': 0.0, 'init_stdev': 1.0, 'num_epochs': 20, 'n_hidden': 127, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.0, 'embedding_size': 8}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 0.745467\n",
      "Step 200, Train Loss: 0.706487\n",
      "Step 400, Train Loss: 0.689145\n",
      "Step 600, Train Loss: 0.672164\n",
      "Step 800, Train Loss: 0.663088\n",
      "----End epoch 0, Val Loss: 0.653711\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_11/epoch0\\\\saved_model.pb'\n",
      "Step 1000, Train Loss: 0.646482\n",
      "Step 1200, Train Loss: 0.628245\n",
      "Step 1400, Train Loss: 0.615342\n",
      "Step 1600, Train Loss: 0.598985\n",
      "Step 1800, Train Loss: 0.575794\n",
      "----End epoch 1, Val Loss: 0.568727\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_11/epoch1\\\\saved_model.pb'\n",
      "Step 2000, Train Loss: 0.561442\n",
      "Step 2200, Train Loss: 0.548209\n",
      "Step 2400, Train Loss: 0.49967\n",
      "Step 2600, Train Loss: 0.494894\n",
      "Step 2800, Train Loss: 0.479382\n",
      "----End epoch 2, Val Loss: 0.465962\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_11/epoch2\\\\saved_model.pb'\n",
      "Step 3000, Train Loss: 0.445579\n",
      "Step 3200, Train Loss: 0.439414\n",
      "Step 3400, Train Loss: 0.412534\n",
      "Step 3600, Train Loss: 0.41515\n",
      "Step 3800, Train Loss: 0.381932\n",
      "----End epoch 3, Val Loss: 0.395517\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_11/epoch3\\\\saved_model.pb'\n",
      "Step 4000, Train Loss: 0.381858\n",
      "Step 4200, Train Loss: 0.327769\n",
      "Step 4400, Train Loss: 0.336109\n",
      "Step 4600, Train Loss: 0.316641\n",
      "----End epoch 4, Val Loss: 0.293635\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_11/epoch4\\\\saved_model.pb'\n",
      "Step 4800, Train Loss: 0.279114\n",
      "Step 5000, Train Loss: 0.265333\n",
      "Step 5200, Train Loss: 0.244382\n",
      "Step 5400, Train Loss: 0.245078\n",
      "Step 5600, Train Loss: 0.204815\n",
      "----End epoch 5, Val Loss: 0.218488\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_11/epoch5\\\\saved_model.pb'\n",
      "Step 5800, Train Loss: 0.207148\n",
      "Step 6000, Train Loss: 0.195014\n",
      "Step 6200, Train Loss: 0.193139\n",
      "Step 6400, Train Loss: 0.187896\n",
      "Step 6600, Train Loss: 0.175036\n",
      "----End epoch 6, Val Loss: 0.171162\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_11/epoch6\\\\saved_model.pb'\n",
      "Step 6800, Train Loss: 0.156978\n",
      "Step 7000, Train Loss: 0.165201\n",
      "Step 7200, Train Loss: 0.168362\n",
      "Step 7400, Train Loss: 0.160599\n",
      "Step 7600, Train Loss: 0.155452\n",
      "----End epoch 7, Val Loss: 0.140099\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_11/epoch7\\\\saved_model.pb'\n",
      "Step 7800, Train Loss: 0.138538\n",
      "Step 8000, Train Loss: 0.140142\n",
      "Step 8200, Train Loss: 0.138928\n",
      "Step 8400, Train Loss: 0.138731\n",
      "----End epoch 8, Val Loss: 0.13261\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_11/epoch8\\\\saved_model.pb'\n",
      "   12 | 35m38s |   -0.13261 |     256.0000 |    0.0000 |           8.0000 |       1.0000 |    0.0000 |       0.0000 |          0.0001 |   127.1831 |      1.0000 |     1.0000 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 1.0, 'optimizer': 'adam', 'batch_size': 32, 'dropout': 0.75, 'init_stdev': 0.0001, 'num_epochs': 20, 'n_hidden': 25, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.0, 'embedding_size': 128}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 0.600342\n",
      "Step 200, Train Loss: 0.1942\n",
      "Step 400, Train Loss: 0.161883\n",
      "Step 600, Train Loss: 0.157918\n",
      "Step 800, Train Loss: 0.170886\n",
      "Step 1000, Train Loss: 0.167666\n",
      "Step 1200, Train Loss: 0.168236\n",
      "Step 1400, Train Loss: 4.12974\n",
      "Step 1600, Train Loss: 0.220974\n",
      "Step 1800, Train Loss: 0.142369\n",
      "Step 2000, Train Loss: 0.2239\n",
      "Step 2200, Train Loss: 0.215838\n",
      "Step 2400, Train Loss: 0.153588\n",
      "Step 2600, Train Loss: 0.167935\n",
      "Step 2800, Train Loss: 0.143858\n",
      "Step 3000, Train Loss: 13.6899\n",
      "Step 3200, Train Loss: 0.179779\n",
      "Step 3400, Train Loss: 0.152825\n",
      "Step 3600, Train Loss: 0.158293\n",
      "Step 3800, Train Loss: 0.139867\n",
      "Step 4000, Train Loss: 0.157764\n",
      "Step 4200, Train Loss: 0.535511\n",
      "Step 4400, Train Loss: 0.195121\n",
      "Step 4600, Train Loss: 0.201917\n",
      "Step 4800, Train Loss: 2.34701\n",
      "Step 5000, Train Loss: 0.30015\n",
      "Step 5200, Train Loss: 2.72149\n",
      "Step 5400, Train Loss: 0.165159\n",
      "Step 5600, Train Loss: 0.149478\n",
      "Step 5800, Train Loss: 0.183678\n",
      "Step 6000, Train Loss: 0.176051\n",
      "Step 6200, Train Loss: 0.165714\n",
      "Step 6400, Train Loss: 17.278\n",
      "Step 6600, Train Loss: 0.162915\n",
      "Step 6800, Train Loss: 0.133494\n",
      "Step 7000, Train Loss: 0.173552\n",
      "Step 7200, Train Loss: 5.01291\n",
      "Step 7400, Train Loss: 0.145351\n",
      "Step 7600, Train Loss: 0.150622\n",
      "----End epoch 0, Val Loss: 0.15998\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_12/epoch0\\\\saved_model.pb'\n",
      "Step 7800, Train Loss: 0.171243\n",
      "Step 8000, Train Loss: 0.121393\n",
      "Step 8200, Train Loss: 0.172813\n",
      "Step 8400, Train Loss: 0.141575\n",
      "Step 8600, Train Loss: 0.16373\n",
      "Step 8800, Train Loss: 0.16192\n",
      "Step 9000, Train Loss: 0.149146\n",
      "Step 9200, Train Loss: 12.3918\n",
      "Step 9400, Train Loss: 0.160468\n",
      "Step 9600, Train Loss: 0.18587\n",
      "Step 9800, Train Loss: 0.178977\n",
      "Step 10000, Train Loss: 1.76354\n",
      "Step 10200, Train Loss: 0.173362\n",
      "Step 10400, Train Loss: 30.1154\n",
      "Step 10600, Train Loss: 5.14734\n",
      "Step 10800, Train Loss: 18.8423\n",
      "Step 11000, Train Loss: 36.9766\n",
      "Step 11200, Train Loss: 2.82223\n",
      "Step 11400, Train Loss: 1.97847\n",
      "Step 11600, Train Loss: 0.899852\n",
      "Step 11800, Train Loss: 0.171846\n",
      "Step 12000, Train Loss: 0.229739\n",
      "Step 12200, Train Loss: 0.208741\n",
      "Step 12400, Train Loss: 4.30783\n",
      "Step 12600, Train Loss: 5.30756\n",
      "Step 12800, Train Loss: 0.753908\n",
      "Step 13000, Train Loss: 0.22103\n",
      "Step 13200, Train Loss: 0.159867\n",
      "Step 13400, Train Loss: 3.01037\n",
      "Step 13600, Train Loss: 0.171976\n",
      "Step 13800, Train Loss: 20.4882\n",
      "Step 14000, Train Loss: 4.7564\n",
      "Step 14200, Train Loss: 1.58217\n",
      "Step 14400, Train Loss: 21.0317\n",
      "Step 14600, Train Loss: 4.76359\n",
      "Step 14800, Train Loss: 3.20612\n",
      "Step 15000, Train Loss: 0.219455\n",
      "Step 15200, Train Loss: 14.8098\n",
      "----End epoch 1, Val Loss: 10.4768\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_12/epoch1\\\\saved_model.pb'\n",
      "   13 | 09m04s |   -0.15998 |      32.0000 |    0.7500 |         128.0000 |       0.0001 |    0.0000 |       0.0000 |          1.0000 |    25.0000 |      0.0000 |     0.0000 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.0001, 'optimizer': 'adam', 'batch_size': 256, 'dropout': 0.0, 'init_stdev': 1.0, 'num_epochs': 20, 'n_hidden': 70, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.0, 'embedding_size': 67}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 1.13977\n",
      "Step 200, Train Loss: 0.806018\n",
      "Step 400, Train Loss: 0.775036\n",
      "Step 600, Train Loss: 0.72644\n",
      "Step 800, Train Loss: 0.669213\n",
      "----End epoch 0, Val Loss: 0.616359\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_13/epoch0\\\\saved_model.pb'\n",
      "Step 1000, Train Loss: 0.610725\n",
      "Step 1200, Train Loss: 0.540885\n",
      "Step 1400, Train Loss: 0.496183\n",
      "Step 1600, Train Loss: 0.454847\n",
      "Step 1800, Train Loss: 0.482325\n",
      "----End epoch 1, Val Loss: 0.428471\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_13/epoch1\\\\saved_model.pb'\n",
      "Step 2000, Train Loss: 0.389282\n",
      "Step 2200, Train Loss: 0.368842\n",
      "Step 2400, Train Loss: 0.370867\n",
      "Step 2600, Train Loss: 0.328388\n",
      "Step 2800, Train Loss: 0.279862\n",
      "----End epoch 2, Val Loss: 0.279408\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_13/epoch2\\\\saved_model.pb'\n",
      "Step 3000, Train Loss: 0.283433\n",
      "Step 3200, Train Loss: 0.284277\n",
      "Step 3400, Train Loss: 0.25089\n",
      "Step 3600, Train Loss: 0.247494\n",
      "Step 3800, Train Loss: 0.234223\n",
      "----End epoch 3, Val Loss: 0.242461\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_13/epoch3\\\\saved_model.pb'\n",
      "Step 4000, Train Loss: 0.213158\n",
      "Step 4200, Train Loss: 0.204896\n",
      "Step 4400, Train Loss: 0.168764\n",
      "Step 4600, Train Loss: 0.183794\n",
      "----End epoch 4, Val Loss: 0.164432\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_13/epoch4\\\\saved_model.pb'\n",
      "Step 4800, Train Loss: 0.148752\n",
      "Step 5000, Train Loss: 0.13398\n",
      "Step 5200, Train Loss: 0.130097\n",
      "Step 5400, Train Loss: 0.12991\n",
      "Step 5600, Train Loss: 0.106379\n",
      "----End epoch 5, Val Loss: 0.0926174\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_13/epoch5\\\\saved_model.pb'\n",
      "Step 5800, Train Loss: 0.111344\n",
      "Step 6000, Train Loss: 0.10566\n",
      "Step 6200, Train Loss: 0.0845972\n",
      "Step 6400, Train Loss: 0.0961099\n",
      "Step 6600, Train Loss: 0.0889487\n",
      "----End epoch 6, Val Loss: 0.0979868\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_13/epoch6\\\\saved_model.pb'\n",
      "Step 6800, Train Loss: 0.0911314\n",
      "Step 7000, Train Loss: 0.097774\n",
      "Step 7200, Train Loss: 0.0891224\n",
      "Step 7400, Train Loss: 0.0898409\n",
      "Step 7600, Train Loss: 0.0893653\n",
      "----End epoch 7, Val Loss: 0.0912516\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_13/epoch7\\\\saved_model.pb'\n",
      "Step 7800, Train Loss: 0.0831656\n",
      "Step 8000, Train Loss: 0.0702544\n",
      "Step 8200, Train Loss: 0.080915\n",
      "Step 8400, Train Loss: 0.0959233\n",
      "----End epoch 8, Val Loss: 0.0730692\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_13/epoch8\\\\saved_model.pb'\n",
      "Step 8600, Train Loss: 0.076319\n",
      "Step 8800, Train Loss: 0.0738254\n",
      "Step 9000, Train Loss: 0.086745\n",
      "Step 9200, Train Loss: 0.0882611\n",
      "Step 9400, Train Loss: 0.0705936\n",
      "----End epoch 9, Val Loss: 0.0637387\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_13/epoch9\\\\saved_model.pb'\n",
      "Step 9600, Train Loss: 0.0809321\n",
      "Step 9800, Train Loss: 0.0873358\n",
      "Step 10000, Train Loss: 0.0622611\n",
      "Step 10200, Train Loss: 0.0725788\n",
      "Step 10400, Train Loss: 0.0922034\n",
      "----End epoch 10, Val Loss: 0.0809553\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_13/epoch10\\\\saved_model.pb'\n",
      "   14 | 34m23s | \u001b[35m  -0.06374\u001b[0m | \u001b[32m    256.0000\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m         67.4297\u001b[0m | \u001b[32m      1.0000\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m      1.0000\u001b[0m | \u001b[32m         0.0001\u001b[0m | \u001b[32m   70.8578\u001b[0m | \u001b[32m     1.0000\u001b[0m | \u001b[32m    0.0000\u001b[0m | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.0001, 'optimizer': 'adam', 'batch_size': 166, 'dropout': 0.0, 'init_stdev': 1.0, 'num_epochs': 20, 'n_hidden': 111, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.10000000000000001, 'embedding_size': 128}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 482.595\n",
      "Step 200, Train Loss: 460.491\n",
      "Step 400, Train Loss: 442.247\n",
      "Step 600, Train Loss: 426.287\n",
      "Step 800, Train Loss: 411.845\n",
      "Step 1000, Train Loss: 398.448\n",
      "Step 1200, Train Loss: 385.773\n",
      "Step 1400, Train Loss: 373.64\n",
      "----End epoch 0, Val Loss: 369.322\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_14/epoch0\\\\saved_model.pb'\n",
      "Step 1600, Train Loss: 361.939\n",
      "Step 1800, Train Loss: 350.624\n",
      "Step 2000, Train Loss: 339.651\n",
      "Step 2200, Train Loss: 328.991\n",
      "Step 2400, Train Loss: 318.652\n",
      "Step 2600, Train Loss: 308.592\n",
      "Step 2800, Train Loss: 298.829\n",
      "----End epoch 1, Val Loss: 291.91\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_14/epoch1\\\\saved_model.pb'\n",
      "   15 | 10m49s | -291.91028 |     166.3595 |    0.0000 |         128.0000 |       1.0000 |    0.1000 |       0.0000 |          0.0001 |   111.5417 |      0.0000 |     1.0000 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.22634488806480685, 'optimizer': 'adam', 'batch_size': 132, 'dropout': 0.46264221063944289, 'init_stdev': 0.24647326201491307, 'num_epochs': 20, 'n_hidden': 249, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.015675437959003159, 'embedding_size': 121}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 110.68\n",
      "Step 200, Train Loss: 0.144048\n",
      "Step 400, Train Loss: 0.1427\n",
      "Step 600, Train Loss: 0.144442\n",
      "Step 800, Train Loss: 0.139849\n",
      "Step 1000, Train Loss: 0.139988\n",
      "Step 1200, Train Loss: 0.144207\n",
      "Step 1400, Train Loss: 0.149604\n",
      "Step 1600, Train Loss: 0.216564\n",
      "Step 1800, Train Loss: 0.222392\n",
      "----End epoch 0, Val Loss: 0.232226\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_15/epoch0\\\\saved_model.pb'\n",
      "Step 2000, Train Loss: 0.301777\n",
      "Step 2200, Train Loss: 0.25573\n",
      "Step 2400, Train Loss: 0.286138\n",
      "Step 2600, Train Loss: 0.281273\n",
      "Step 2800, Train Loss: 0.276479\n",
      "Step 3000, Train Loss: 0.260971\n",
      "Step 3200, Train Loss: 0.267558\n",
      "Step 3400, Train Loss: 0.261773\n",
      "Step 3600, Train Loss: 0.27991\n",
      "----End epoch 1, Val Loss: 0.239058\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_15/epoch1\\\\saved_model.pb'\n",
      "Step 3800, Train Loss: 0.254179\n",
      "Step 4000, Train Loss: 0.276893\n",
      "Step 4200, Train Loss: 0.248906\n",
      "Step 4400, Train Loss: 0.276773\n",
      "Step 4600, Train Loss: 0.25617\n",
      "Step 4800, Train Loss: 0.261801\n",
      "Step 5000, Train Loss: 0.254792\n",
      "Step 5200, Train Loss: 0.270507\n",
      "Step 5400, Train Loss: 0.275011\n",
      "----End epoch 2, Val Loss: 0.267977\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_15/epoch2\\\\saved_model.pb'\n",
      "Step 5600, Train Loss: 0.268338\n",
      "Step 5800, Train Loss: 0.262774\n",
      "Step 6000, Train Loss: 0.217017\n",
      "Step 6200, Train Loss: 0.303378\n",
      "Step 6400, Train Loss: 0.232146\n",
      "Step 6600, Train Loss: 0.276388\n",
      "Step 6800, Train Loss: 0.254202\n",
      "Step 7000, Train Loss: 0.266826\n",
      "Step 7200, Train Loss: 0.281246\n",
      "Step 7400, Train Loss: 0.24836\n",
      "----End epoch 3, Val Loss: 0.256287\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_15/epoch3\\\\saved_model.pb'\n",
      "Step 7600, Train Loss: 0.275332\n",
      "Step 7800, Train Loss: 0.24591\n",
      "Step 8000, Train Loss: 0.273173\n",
      "Step 8200, Train Loss: 0.261887\n",
      "Step 8400, Train Loss: 0.256781\n",
      "Step 8600, Train Loss: 0.261116\n",
      "Step 8800, Train Loss: 0.256653\n",
      "Step 9000, Train Loss: 0.258111\n",
      "Step 9200, Train Loss: 0.261816\n",
      "----End epoch 4, Val Loss: 0.261402\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_15/epoch4\\\\saved_model.pb'\n",
      "Step 9400, Train Loss: 0.263691\n",
      "Step 9600, Train Loss: 0.296216\n",
      "Step 9800, Train Loss: 0.256055\n",
      "Step 10000, Train Loss: 0.289456\n",
      "Step 10200, Train Loss: 0.229947\n",
      "Step 10400, Train Loss: 0.283782\n",
      "Step 10600, Train Loss: 0.2481\n",
      "Step 10800, Train Loss: 0.270573\n",
      "Step 11000, Train Loss: 0.260463\n",
      "----End epoch 5, Val Loss: 0.251142\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_15/epoch5\\\\saved_model.pb'\n",
      "Step 11200, Train Loss: 0.254796\n",
      "Step 11400, Train Loss: 0.262094\n",
      "Step 11600, Train Loss: 0.254399\n",
      "Step 11800, Train Loss: 0.254871\n",
      "Step 12000, Train Loss: 0.278103\n",
      "Step 12200, Train Loss: 0.217525\n",
      "Step 12400, Train Loss: 0.284482\n",
      "Step 12600, Train Loss: 0.250536\n",
      "Step 12800, Train Loss: 0.265101\n",
      "----End epoch 6, Val Loss: 0.280021\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_15/epoch6\\\\saved_model.pb'\n",
      "   16 | 111m31s |   -0.23223 |     132.9219 |    0.4626 |         121.2308 |       0.2465 |    0.0157 |       0.2842 |          0.2263 |   249.7829 |      0.5774 |     0.2478 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.39144953904603785, 'optimizer': 'adam', 'batch_size': 172, 'dropout': 0.13666673050536413, 'init_stdev': 0.94864772512767381, 'num_epochs': 20, 'n_hidden': 221, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.035557076944567716, 'embedding_size': 20}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 503.348\n",
      "Step 200, Train Loss: 0.142194\n",
      "Step 400, Train Loss: 0.146646\n",
      "Step 600, Train Loss: 0.145393\n",
      "Step 800, Train Loss: 0.137474\n",
      "Step 1000, Train Loss: 0.140806\n",
      "Step 1200, Train Loss: 0.138745\n",
      "Step 1400, Train Loss: 0.149544\n",
      "----End epoch 0, Val Loss: 0.14351\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_16/epoch0\\\\saved_model.pb'\n",
      "Step 1600, Train Loss: 0.14568\n",
      "Step 1800, Train Loss: 0.831873\n",
      "Step 2000, Train Loss: 0.827014\n",
      "Step 2200, Train Loss: 0.284661\n",
      "Step 2400, Train Loss: 0.952392\n",
      "Step 2600, Train Loss: 0.493009\n",
      "Step 2800, Train Loss: 0.60854\n",
      "----End epoch 1, Val Loss: 0.649417\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_16/epoch1\\\\saved_model.pb'\n",
      "Step 3000, Train Loss: 0.710024\n",
      "Step 3200, Train Loss: 0.485926\n",
      "Step 3400, Train Loss: 0.603166\n",
      "Step 3600, Train Loss: 0.579651\n",
      "Step 3800, Train Loss: 0.573459\n",
      "Step 4000, Train Loss: 0.609062\n",
      "Step 4200, Train Loss: 0.572689\n",
      "----End epoch 2, Val Loss: 0.547177\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_16/epoch2\\\\saved_model.pb'\n",
      "Step 4400, Train Loss: 0.616065\n",
      "Step 4600, Train Loss: 0.588136\n",
      "Step 4800, Train Loss: 0.592186\n",
      "Step 5000, Train Loss: 0.613797\n",
      "Step 5200, Train Loss: 0.59315\n",
      "Step 5400, Train Loss: 0.611887\n",
      "Step 5600, Train Loss: 0.598123\n",
      "----End epoch 3, Val Loss: 0.510839\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_16/epoch3\\\\saved_model.pb'\n",
      "   17 | 29m22s |   -0.14351 |     172.2848 |    0.1367 |          20.5159 |       0.9486 |    0.0356 |       0.6596 |          0.3914 |   221.1964 |      0.9404 |     0.1987 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.84495900700240401, 'optimizer': 'adam', 'batch_size': 66, 'dropout': 0.40949195476958999, 'init_stdev': 0.82998787103709692, 'num_epochs': 20, 'n_hidden': 99, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.052948228953806908, 'embedding_size': 95}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 1366.26\n",
      "Step 200, Train Loss: 0.142759\n",
      "Step 400, Train Loss: 0.148167\n",
      "Step 600, Train Loss: 0.145419\n",
      "Step 800, Train Loss: 0.142919\n",
      "Step 1000, Train Loss: 0.138258\n",
      "Step 1200, Train Loss: 0.153136\n",
      "Step 1400, Train Loss: 0.171561\n",
      "Step 1600, Train Loss: 0.177368\n",
      "Step 1800, Train Loss: 0.511352\n",
      "Step 2000, Train Loss: 2.69555\n",
      "Step 2200, Train Loss: 0.577028\n",
      "Step 2400, Train Loss: 1.30578\n",
      "Step 2600, Train Loss: 1.78891\n",
      "Step 2800, Train Loss: 1.14614\n",
      "Step 3000, Train Loss: 1.40619\n",
      "Step 3200, Train Loss: 1.46166\n",
      "Step 3400, Train Loss: 1.35462\n",
      "Step 3600, Train Loss: 1.39964\n",
      "----End epoch 0, Val Loss: 1.40079\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_17/epoch0\\\\saved_model.pb'\n",
      "Step 3800, Train Loss: 1.27995\n",
      "Step 4000, Train Loss: 1.43849\n",
      "Step 4200, Train Loss: 1.33693\n",
      "Step 4400, Train Loss: 1.45059\n",
      "Step 4600, Train Loss: 1.41892\n",
      "Step 4800, Train Loss: 1.36657\n",
      "Step 5000, Train Loss: 1.44362\n",
      "Step 5200, Train Loss: 1.36387\n",
      "Step 5400, Train Loss: 1.48317\n",
      "Step 5600, Train Loss: 1.35523\n",
      "Step 5800, Train Loss: 1.43097\n",
      "Step 6000, Train Loss: 1.36714\n",
      "Step 6200, Train Loss: 1.3624\n",
      "Step 6400, Train Loss: 1.4235\n",
      "Step 6600, Train Loss: 1.38481\n",
      "Step 6800, Train Loss: 1.42164\n",
      "Step 7000, Train Loss: 1.40515\n",
      "Step 7200, Train Loss: 1.40037\n",
      "Step 7400, Train Loss: 1.40408\n",
      "----End epoch 1, Val Loss: 1.37183\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_17/epoch1\\\\saved_model.pb'\n",
      "Step 7600, Train Loss: 1.40649\n",
      "Step 7800, Train Loss: 1.35131\n",
      "Step 8000, Train Loss: 1.41798\n",
      "Step 8200, Train Loss: 1.37913\n",
      "Step 8400, Train Loss: 1.41205\n",
      "Step 8600, Train Loss: 1.40177\n",
      "Step 8800, Train Loss: 1.40026\n",
      "Step 9000, Train Loss: 1.3882\n",
      "Step 9200, Train Loss: 1.38079\n",
      "Step 9400, Train Loss: 1.40571\n",
      "Step 9600, Train Loss: 1.4407\n",
      "Step 9800, Train Loss: 1.34356\n",
      "Step 10000, Train Loss: 1.43763\n",
      "Step 10200, Train Loss: 1.37248\n",
      "Step 10400, Train Loss: 1.4535\n",
      "Step 10600, Train Loss: 1.37932\n",
      "Step 10800, Train Loss: 1.43409\n",
      "Step 11000, Train Loss: 1.3927\n",
      "----End epoch 2, Val Loss: 1.38015\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_17/epoch2\\\\saved_model.pb'\n",
      "Step 11200, Train Loss: 1.39251\n",
      "Step 11400, Train Loss: 1.42464\n",
      "Step 11600, Train Loss: 1.40025\n",
      "Step 11800, Train Loss: 1.37145\n",
      "Step 12000, Train Loss: 1.35609\n",
      "Step 12200, Train Loss: 1.4517\n",
      "Step 12400, Train Loss: 1.44468\n",
      "Step 12600, Train Loss: 1.32723\n",
      "Step 12800, Train Loss: 1.43789\n",
      "Step 13000, Train Loss: 1.42777\n",
      "Step 13200, Train Loss: 1.38493\n",
      "Step 13400, Train Loss: 1.3897\n",
      "Step 13600, Train Loss: 1.35142\n",
      "Step 13800, Train Loss: 1.42304\n",
      "Step 14000, Train Loss: 1.38921\n",
      "Step 14200, Train Loss: 1.40444\n",
      "Step 14400, Train Loss: 1.39472\n",
      "Step 14600, Train Loss: 1.42455\n",
      "Step 14800, Train Loss: 1.44173\n",
      "----End epoch 3, Val Loss: 1.42822\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_17/epoch3\\\\saved_model.pb'\n",
      "   18 | 23m04s |   -1.37183 |      66.2248 |    0.4095 |          95.3770 |       0.8300 |    0.0529 |       0.1024 |          0.8450 |    99.2953 |      0.3530 |     0.0915 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.24956620492873482, 'optimizer': 'adam', 'batch_size': 183, 'dropout': 0.75, 'init_stdev': 0.0001, 'num_epochs': 20, 'n_hidden': 62, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.0, 'embedding_size': 15}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 0.749399\n",
      "Step 200, Train Loss: 0.124912\n",
      "Step 400, Train Loss: 0.109719\n",
      "Step 600, Train Loss: 0.125027\n",
      "Step 800, Train Loss: 0.138172\n",
      "Step 1000, Train Loss: 0.132027\n",
      "Step 1200, Train Loss: 0.127189\n",
      "----End epoch 0, Val Loss: 0.146361\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_18/epoch0\\\\saved_model.pb'\n",
      "Step 1400, Train Loss: 0.134767\n",
      "Step 1600, Train Loss: 0.132515\n",
      "Step 1800, Train Loss: 0.15085\n",
      "Step 2000, Train Loss: 0.145345\n",
      "Step 2200, Train Loss: 0.143173\n",
      "Step 2400, Train Loss: 0.139725\n",
      "Step 2600, Train Loss: 0.137315\n",
      "----End epoch 1, Val Loss: 0.155995\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_18/epoch1\\\\saved_model.pb'\n",
      "Step 2800, Train Loss: 0.142349\n",
      "Step 3000, Train Loss: 0.147367\n",
      "Step 3200, Train Loss: 0.140315\n",
      "Step 3400, Train Loss: 0.140472\n",
      "Step 3600, Train Loss: 0.137263\n",
      "Step 3800, Train Loss: 0.142017\n",
      "Step 4000, Train Loss: 0.145472\n",
      "----End epoch 2, Val Loss: 0.139918\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_18/epoch2\\\\saved_model.pb'\n",
      "Step 4200, Train Loss: 0.144496\n",
      "Step 4400, Train Loss: 0.141748\n",
      "Step 4600, Train Loss: 0.147865\n",
      "Step 4800, Train Loss: 0.143979\n",
      "Step 5000, Train Loss: 0.145676\n",
      "Step 5200, Train Loss: 0.140334\n",
      "----End epoch 3, Val Loss: 0.137884\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_18/epoch3\\\\saved_model.pb'\n",
      "Step 5400, Train Loss: 0.135978\n",
      "Step 5600, Train Loss: 0.143253\n",
      "Step 5800, Train Loss: 0.136261\n",
      "Step 6000, Train Loss: 0.139984\n",
      "Step 6200, Train Loss: 0.147832\n",
      "Step 6400, Train Loss: 0.14105\n",
      "Step 6600, Train Loss: 0.136269\n",
      "----End epoch 4, Val Loss: 0.135013\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_18/epoch4\\\\saved_model.pb'\n",
      "Step 6800, Train Loss: 0.144185\n",
      "Step 7000, Train Loss: 0.138592\n",
      "Step 7200, Train Loss: 0.134733\n",
      "Step 7400, Train Loss: 0.142101\n",
      "Step 7600, Train Loss: 0.136075\n",
      "Step 7800, Train Loss: 0.141794\n",
      "Step 8000, Train Loss: 0.143748\n",
      "----End epoch 5, Val Loss: 0.142201\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_18/epoch5\\\\saved_model.pb'\n",
      "Step 8200, Train Loss: 0.142379\n",
      "Step 8400, Train Loss: 0.141701\n",
      "Step 8600, Train Loss: 0.137815\n",
      "Step 8800, Train Loss: 0.146695\n",
      "Step 9000, Train Loss: 0.142634\n",
      "Step 9200, Train Loss: 0.136456\n",
      "----End epoch 6, Val Loss: 0.143187\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_18/epoch6\\\\saved_model.pb'\n",
      "Step 9400, Train Loss: 0.141087\n",
      "Step 9600, Train Loss: 0.140677\n",
      "Step 9800, Train Loss: 0.143827\n",
      "Step 10000, Train Loss: 0.151029\n",
      "Step 10200, Train Loss: 0.139645\n",
      "Step 10400, Train Loss: 0.154403\n",
      "Step 10600, Train Loss: 0.150909\n",
      "----End epoch 7, Val Loss: 0.133355\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_18/epoch7\\\\saved_model.pb'\n",
      "Step 10800, Train Loss: 0.13749\n",
      "Step 11000, Train Loss: 0.143722\n",
      "Step 11200, Train Loss: 0.142967\n",
      "Step 11400, Train Loss: 0.137553\n",
      "Step 11600, Train Loss: 0.140334\n",
      "Step 11800, Train Loss: 0.148969\n",
      "Step 12000, Train Loss: 0.142905\n",
      "----End epoch 8, Val Loss: 0.133783\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_18/epoch8\\\\saved_model.pb'\n",
      "   19 | 27m02s |   -0.13335 |     183.7259 |    0.7500 |          15.2299 |       0.0001 |    0.0000 |       1.0000 |          0.2496 |    62.0655 |      1.0000 |     0.0000 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.95063716229653872, 'optimizer': 'adam', 'batch_size': 37, 'dropout': 0.23992729842015392, 'init_stdev': 0.86525103935373981, 'num_epochs': 20, 'n_hidden': 249, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.095607682782461484, 'embedding_size': 119}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 15004.2\n",
      "Step 200, Train Loss: 0.146193\n",
      "Step 400, Train Loss: 0.149924\n",
      "Step 600, Train Loss: 0.159663\n",
      "Step 800, Train Loss: 0.135509\n",
      "Step 1000, Train Loss: 0.149179\n",
      "Step 1200, Train Loss: 0.257368\n",
      "Step 1400, Train Loss: 0.385734\n",
      "Step 1600, Train Loss: 0.733915\n",
      "Step 1800, Train Loss: 1.48059\n",
      "Step 2000, Train Loss: 45.4819\n",
      "Step 2200, Train Loss: 3.0023\n",
      "Step 2400, Train Loss: 9.77449\n",
      "Step 2600, Train Loss: 17.9793\n",
      "Step 2800, Train Loss: 9.90344\n",
      "Step 3000, Train Loss: 13.6624\n",
      "Step 3200, Train Loss: 12.9789\n",
      "Step 3400, Train Loss: 14.2442\n",
      "Step 3600, Train Loss: 11.7087\n",
      "Step 3800, Train Loss: 13.4786\n",
      "Step 4000, Train Loss: 12.6714\n",
      "Step 4200, Train Loss: 13.5578\n",
      "Step 4400, Train Loss: 13.6463\n",
      "Step 4600, Train Loss: 12.5674\n",
      "Step 4800, Train Loss: 12.5328\n",
      "Step 5000, Train Loss: 12.3553\n",
      "Step 5200, Train Loss: 12.9894\n",
      "Step 5400, Train Loss: 13.0207\n",
      "Step 5600, Train Loss: 13.0342\n",
      "Step 5800, Train Loss: 13.0826\n",
      "Step 6000, Train Loss: 12.7055\n",
      "Step 6200, Train Loss: 13.6584\n",
      "Step 6400, Train Loss: 12.0443\n",
      "Step 6600, Train Loss: 13.6718\n",
      "----End epoch 0, Val Loss: 13.3441\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_19/epoch0\\\\saved_model.pb'\n",
      "Step 6800, Train Loss: 12.3399\n",
      "Step 7000, Train Loss: 13.5707\n",
      "Step 7200, Train Loss: 13.4254\n",
      "Step 7400, Train Loss: 13.2761\n",
      "Step 7600, Train Loss: 13.3053\n",
      "Step 7800, Train Loss: 12.9951\n",
      "Step 8000, Train Loss: 12.9544\n",
      "Step 8200, Train Loss: 13.5803\n",
      "Step 8400, Train Loss: 12.6782\n",
      "Step 8600, Train Loss: 13.5274\n",
      "Step 8800, Train Loss: 12.949\n",
      "Step 9000, Train Loss: 12.9817\n",
      "Step 9200, Train Loss: 13.3775\n",
      "Step 9400, Train Loss: 12.7256\n",
      "Step 9600, Train Loss: 13.3534\n",
      "Step 9800, Train Loss: 12.4634\n",
      "Step 10000, Train Loss: 13.3443\n",
      "Step 10200, Train Loss: 13.0861\n",
      "Step 10400, Train Loss: 13.0602\n",
      "Step 10600, Train Loss: 13.3302\n",
      "Step 10800, Train Loss: 12.8902\n",
      "Step 11000, Train Loss: 13.0647\n",
      "Step 11200, Train Loss: 12.9255\n",
      "Step 11400, Train Loss: 13.2431\n",
      "Step 11600, Train Loss: 13.2256\n",
      "Step 11800, Train Loss: 12.9184\n",
      "Step 12000, Train Loss: 13.3377\n",
      "Step 12200, Train Loss: 13.0041\n",
      "Step 12400, Train Loss: 12.8779\n",
      "Step 12600, Train Loss: 13.1516\n",
      "Step 12800, Train Loss: 13.1272\n",
      "Step 13000, Train Loss: 13.3718\n",
      "Step 13200, Train Loss: 13.1789\n",
      "----End epoch 1, Val Loss: 13.3463\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_19/epoch1\\\\saved_model.pb'\n",
      "   20 | 36m14s |  -13.34407 |      37.3826 |    0.2399 |         119.9865 |       0.8653 |    0.0956 |       0.3721 |          0.9506 |   249.3839 |      0.2131 |     0.5719 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.0001, 'optimizer': 'adam', 'batch_size': 32, 'dropout': 0.75, 'init_stdev': 1.0, 'num_epochs': 20, 'n_hidden': 81, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.10000000000000001, 'embedding_size': 8}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 39.3438\n",
      "Step 200, Train Loss: 35.5835\n",
      "Step 400, Train Loss: 32.8611\n",
      "Step 600, Train Loss: 30.8395\n",
      "Step 800, Train Loss: 29.2849\n",
      "Step 1000, Train Loss: 28.038\n",
      "Step 1200, Train Loss: 26.9639\n",
      "Step 1400, Train Loss: 26.021\n",
      "Step 1600, Train Loss: 25.1603\n",
      "Step 1800, Train Loss: 24.3577\n",
      "Step 2000, Train Loss: 23.5746\n",
      "Step 2200, Train Loss: 22.8267\n",
      "Step 2400, Train Loss: 22.1057\n",
      "Step 2600, Train Loss: 21.4008\n",
      "Step 2800, Train Loss: 20.7146\n",
      "Step 3000, Train Loss: 20.0481\n",
      "Step 3200, Train Loss: 19.4023\n",
      "Step 3400, Train Loss: 18.7741\n",
      "Step 3600, Train Loss: 18.167\n",
      "Step 3800, Train Loss: 17.5624\n",
      "Step 4000, Train Loss: 16.9941\n",
      "Step 4200, Train Loss: 16.4259\n",
      "Step 4400, Train Loss: 15.8886\n",
      "Step 4600, Train Loss: 15.3657\n",
      "Step 4800, Train Loss: 14.8381\n",
      "Step 5000, Train Loss: 14.335\n",
      "Step 5200, Train Loss: 13.861\n",
      "Step 5400, Train Loss: 13.383\n",
      "Step 5600, Train Loss: 12.9144\n",
      "Step 5800, Train Loss: 12.4663\n",
      "Step 6000, Train Loss: 12.0345\n",
      "Step 6200, Train Loss: 11.6209\n",
      "Step 6400, Train Loss: 11.2148\n",
      "Step 6600, Train Loss: 10.812\n",
      "Step 6800, Train Loss: 10.4305\n",
      "Step 7000, Train Loss: 10.0652\n",
      "Step 7200, Train Loss: 9.69516\n",
      "Step 7400, Train Loss: 9.33411\n",
      "Step 7600, Train Loss: 9.00433\n",
      "----End epoch 0, Val Loss: 8.93766\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_20/epoch0\\\\saved_model.pb'\n",
      "Step 7800, Train Loss: 8.67152\n",
      "Step 8000, Train Loss: 8.3615\n",
      "Step 8200, Train Loss: 8.04952\n",
      "Step 8400, Train Loss: 7.7502\n",
      "Step 8600, Train Loss: 7.45804\n",
      "Step 8800, Train Loss: 7.18842\n",
      "Step 9000, Train Loss: 6.91051\n",
      "Step 9200, Train Loss: 6.64558\n",
      "Step 9400, Train Loss: 6.38576\n",
      "Step 9600, Train Loss: 6.14699\n",
      "Step 9800, Train Loss: 5.90723\n",
      "Step 10000, Train Loss: 5.6728\n",
      "Step 10200, Train Loss: 5.46163\n",
      "Step 10400, Train Loss: 5.25996\n",
      "Step 10600, Train Loss: 5.04469\n",
      "Step 10800, Train Loss: 4.83737\n",
      "Step 11000, Train Loss: 4.65449\n",
      "Step 11200, Train Loss: 4.46896\n",
      "Step 11400, Train Loss: 4.30917\n",
      "Step 11600, Train Loss: 4.12822\n",
      "Step 11800, Train Loss: 3.94925\n",
      "Step 12000, Train Loss: 3.79461\n",
      "Step 12200, Train Loss: 3.64235\n",
      "Step 12400, Train Loss: 3.49642\n",
      "Step 12600, Train Loss: 3.35855\n",
      "Step 12800, Train Loss: 3.21437\n",
      "Step 13000, Train Loss: 3.09146\n",
      "Step 13200, Train Loss: 2.95542\n",
      "Step 13400, Train Loss: 2.83222\n",
      "Step 13600, Train Loss: 2.71327\n",
      "Step 13800, Train Loss: 2.6129\n",
      "Step 14000, Train Loss: 2.50316\n",
      "Step 14200, Train Loss: 2.40138\n",
      "Step 14400, Train Loss: 2.2905\n",
      "Step 14600, Train Loss: 2.19909\n",
      "Step 14800, Train Loss: 2.10962\n",
      "Step 15000, Train Loss: 2.01666\n",
      "Step 15200, Train Loss: 1.93722\n",
      "----End epoch 1, Val Loss: 1.91328\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_20/epoch1\\\\saved_model.pb'\n",
      "Step 15400, Train Loss: 1.8603\n",
      "Step 15600, Train Loss: 1.7726\n",
      "Step 15800, Train Loss: 1.69592\n",
      "Step 16000, Train Loss: 1.63626\n",
      "Step 16200, Train Loss: 1.56042\n",
      "Step 16400, Train Loss: 1.49826\n",
      "Step 16600, Train Loss: 1.44548\n",
      "Step 16800, Train Loss: 1.37024\n",
      "Step 17000, Train Loss: 1.3185\n",
      "Step 17200, Train Loss: 1.27182\n",
      "Step 17400, Train Loss: 1.21929\n",
      "Step 17600, Train Loss: 1.16675\n",
      "Step 17800, Train Loss: 1.12162\n",
      "Step 18000, Train Loss: 1.0739\n",
      "Step 18200, Train Loss: 1.03153\n",
      "Step 18400, Train Loss: 0.983492\n",
      "Step 18600, Train Loss: 0.951792\n",
      "Step 18800, Train Loss: 0.911586\n",
      "Step 19000, Train Loss: 0.871929\n",
      "Step 19200, Train Loss: 0.830259\n",
      "Step 19400, Train Loss: 0.807216\n",
      "Step 19600, Train Loss: 0.774871\n",
      "Step 19800, Train Loss: 0.750462\n",
      "Step 20000, Train Loss: 0.726677\n",
      "Step 20200, Train Loss: 0.690434\n",
      "Step 20400, Train Loss: 0.678689\n",
      "Step 20600, Train Loss: 0.645804\n",
      "Step 20800, Train Loss: 0.621573\n",
      "Step 21000, Train Loss: 0.592833\n",
      "Step 21200, Train Loss: 0.592981\n",
      "Step 21400, Train Loss: 0.556172\n",
      "Step 21600, Train Loss: 0.537033\n",
      "Step 21800, Train Loss: 0.52316\n",
      "Step 22000, Train Loss: 0.509735\n",
      "Step 22200, Train Loss: 0.493199\n",
      "Step 22400, Train Loss: 0.47966\n",
      "Step 22600, Train Loss: 0.450838\n",
      "Step 22800, Train Loss: 0.433065\n",
      "----End epoch 2, Val Loss: 0.437714\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_20/epoch2\\\\saved_model.pb'\n",
      "Step 23000, Train Loss: 0.433854\n",
      "Step 23200, Train Loss: 0.428315\n",
      "Step 23400, Train Loss: 0.395135\n",
      "Step 23600, Train Loss: 0.385092\n",
      "Step 23800, Train Loss: 0.385659\n",
      "Step 24000, Train Loss: 0.378211\n",
      "Step 24200, Train Loss: 0.361383\n",
      "Step 24400, Train Loss: 0.3587\n",
      "Step 24600, Train Loss: 0.347001\n",
      "Step 24800, Train Loss: 0.34653\n",
      "Step 25000, Train Loss: 0.343795\n",
      "Step 25200, Train Loss: 0.326839\n",
      "Step 25400, Train Loss: 0.314857\n",
      "Step 25600, Train Loss: 0.311944\n",
      "Step 25800, Train Loss: 0.310152\n",
      "Step 26000, Train Loss: 0.3226\n",
      "Step 26200, Train Loss: 0.294047\n",
      "Step 26400, Train Loss: 0.287968\n",
      "Step 26600, Train Loss: 0.272806\n",
      "Step 26800, Train Loss: 0.272625\n",
      "Step 27000, Train Loss: 0.277562\n",
      "Step 27200, Train Loss: 0.264206\n",
      "Step 27400, Train Loss: 0.282688\n",
      "Step 27600, Train Loss: 0.252357\n",
      "Step 27800, Train Loss: 0.245303\n",
      "Step 28000, Train Loss: 0.263056\n",
      "Step 28200, Train Loss: 0.252126\n",
      "Step 28400, Train Loss: 0.228646\n",
      "Step 28600, Train Loss: 0.239485\n",
      "Step 28800, Train Loss: 0.243025\n",
      "Step 29000, Train Loss: 0.244747\n",
      "Step 29200, Train Loss: 0.22645\n",
      "Step 29400, Train Loss: 0.215851\n",
      "Step 29600, Train Loss: 0.223673\n",
      "Step 29800, Train Loss: 0.208961\n",
      "Step 30000, Train Loss: 0.210473\n",
      "Step 30200, Train Loss: 0.225673\n",
      "Step 30400, Train Loss: 0.21268\n",
      "----End epoch 3, Val Loss: 0.201483\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_20/epoch3\\\\saved_model.pb'\n",
      "Step 30600, Train Loss: 0.207456\n",
      "Step 30800, Train Loss: 0.21577\n",
      "Step 31000, Train Loss: 0.209802\n",
      "Step 31200, Train Loss: 0.192999\n",
      "Step 31400, Train Loss: 0.206331\n",
      "Step 31600, Train Loss: 0.220383\n",
      "Step 31800, Train Loss: 0.181129\n",
      "Step 32000, Train Loss: 0.194722\n",
      "Step 32200, Train Loss: 0.20761\n",
      "Step 32400, Train Loss: 0.192562\n",
      "Step 32600, Train Loss: 0.182003\n",
      "Step 32800, Train Loss: 0.183545\n",
      "Step 33000, Train Loss: 0.196991\n",
      "Step 33200, Train Loss: 0.19616\n",
      "Step 33400, Train Loss: 0.200068\n",
      "Step 33600, Train Loss: 0.186728\n",
      "Step 33800, Train Loss: 0.171893\n",
      "Step 34000, Train Loss: 0.215802\n",
      "Step 34200, Train Loss: 0.188514\n",
      "Step 34400, Train Loss: 0.195116\n",
      "Step 34600, Train Loss: 0.18609\n",
      "Step 34800, Train Loss: 0.183412\n",
      "Step 35000, Train Loss: 0.178103\n",
      "Step 35200, Train Loss: 0.181396\n",
      "Step 35400, Train Loss: 0.197127\n",
      "Step 35600, Train Loss: 0.189953\n",
      "Step 35800, Train Loss: 0.189207\n",
      "Step 36000, Train Loss: 0.177402\n",
      "Step 36200, Train Loss: 0.172818\n",
      "Step 36400, Train Loss: 0.180711\n",
      "Step 36600, Train Loss: 0.182006\n",
      "Step 36800, Train Loss: 0.161127\n",
      "Step 37000, Train Loss: 0.183209\n",
      "Step 37200, Train Loss: 0.179396\n",
      "Step 37400, Train Loss: 0.156829\n",
      "Step 37600, Train Loss: 0.179567\n",
      "Step 37800, Train Loss: 0.168413\n",
      "Step 38000, Train Loss: 0.19634\n",
      "----End epoch 4, Val Loss: 0.169159\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_20/epoch4\\\\saved_model.pb'\n",
      "Step 38200, Train Loss: 0.174307\n",
      "Step 38400, Train Loss: 0.150465\n",
      "Step 38600, Train Loss: 0.166012\n",
      "Step 38800, Train Loss: 0.173753\n",
      "Step 39000, Train Loss: 0.181447\n",
      "Step 39200, Train Loss: 0.183545\n",
      "Step 39400, Train Loss: 0.173616\n",
      "Step 39600, Train Loss: 0.177686\n",
      "Step 39800, Train Loss: 0.174701\n",
      "Step 40000, Train Loss: 0.170211\n",
      "Step 40200, Train Loss: 0.173967\n",
      "Step 40400, Train Loss: 0.162291\n",
      "Step 40600, Train Loss: 0.152476\n",
      "Step 40800, Train Loss: 0.165365\n",
      "Step 41000, Train Loss: 0.17455\n",
      "Step 41200, Train Loss: 0.161595\n",
      "Step 41400, Train Loss: 0.168195\n",
      "Step 41600, Train Loss: 0.174569\n",
      "Step 41800, Train Loss: 0.189374\n",
      "Step 42000, Train Loss: 0.175148\n",
      "Step 42200, Train Loss: 0.158696\n",
      "Step 42400, Train Loss: 0.164076\n",
      "Step 42600, Train Loss: 0.159167\n",
      "Step 42800, Train Loss: 0.165249\n",
      "Step 43000, Train Loss: 0.171729\n",
      "Step 43200, Train Loss: 0.139694\n",
      "Step 43400, Train Loss: 0.180961\n",
      "Step 43600, Train Loss: 0.154374\n",
      "Step 43800, Train Loss: 0.150915\n",
      "Step 44000, Train Loss: 0.156428\n",
      "Step 44200, Train Loss: 0.155784\n",
      "Step 44400, Train Loss: 0.161112\n",
      "Step 44600, Train Loss: 0.144019\n",
      "Step 44800, Train Loss: 0.15929\n",
      "Step 45000, Train Loss: 0.15264\n",
      "Step 45200, Train Loss: 0.140098\n",
      "Step 45400, Train Loss: 0.1685\n",
      "Step 45600, Train Loss: 0.162836\n",
      "Step 45800, Train Loss: 0.159206\n",
      "----End epoch 5, Val Loss: 0.170266\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_20/epoch5\\\\saved_model.pb'\n",
      "Step 46000, Train Loss: 0.160313\n",
      "Step 46200, Train Loss: 0.135234\n",
      "Step 46400, Train Loss: 0.17024\n",
      "Step 46600, Train Loss: 0.131766\n",
      "Step 46800, Train Loss: 0.150826\n",
      "Step 47000, Train Loss: 0.149042\n",
      "Step 47200, Train Loss: 0.160991\n",
      "Step 47400, Train Loss: 0.171399\n",
      "Step 47600, Train Loss: 0.162071\n",
      "Step 47800, Train Loss: 0.151975\n",
      "Step 48000, Train Loss: 0.175849\n",
      "Step 48200, Train Loss: 0.140428\n",
      "Step 48400, Train Loss: 0.150289\n",
      "Step 48600, Train Loss: 0.140653\n",
      "Step 48800, Train Loss: 0.143764\n",
      "Step 49000, Train Loss: 0.147633\n",
      "Step 49200, Train Loss: 0.157695\n",
      "Step 49400, Train Loss: 0.163546\n",
      "Step 49600, Train Loss: 0.148964\n",
      "Step 49800, Train Loss: 0.15727\n",
      "Step 50000, Train Loss: 0.154119\n",
      "Step 50200, Train Loss: 0.142495\n",
      "Step 50400, Train Loss: 0.145962\n",
      "Step 50600, Train Loss: 0.148488\n",
      "Step 50800, Train Loss: 0.153292\n",
      "Step 51000, Train Loss: 0.1411\n",
      "Step 51200, Train Loss: 0.153928\n",
      "Step 51400, Train Loss: 0.138439\n",
      "Step 51600, Train Loss: 0.155672\n",
      "Step 51800, Train Loss: 0.160565\n",
      "Step 52000, Train Loss: 0.135541\n",
      "Step 52200, Train Loss: 0.143266\n",
      "Step 52400, Train Loss: 0.156845\n",
      "Step 52600, Train Loss: 0.138091\n",
      "Step 52800, Train Loss: 0.143289\n",
      "Step 53000, Train Loss: 0.14315\n",
      "Step 53200, Train Loss: 0.155985\n",
      "Step 53400, Train Loss: 0.141005\n",
      "----End epoch 6, Val Loss: 0.159436\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_20/epoch6\\\\saved_model.pb'\n",
      "Step 53600, Train Loss: 0.147945\n",
      "Step 53800, Train Loss: 0.131268\n",
      "Step 54000, Train Loss: 0.144315\n",
      "Step 54200, Train Loss: 0.173152\n",
      "Step 54400, Train Loss: 0.141358\n",
      "Step 54600, Train Loss: 0.149243\n",
      "Step 54800, Train Loss: 0.141021\n",
      "Step 55000, Train Loss: 0.150483\n",
      "Step 55200, Train Loss: 0.140526\n",
      "Step 55400, Train Loss: 0.139823\n",
      "Step 55600, Train Loss: 0.151381\n",
      "Step 55800, Train Loss: 0.151464\n",
      "Step 56000, Train Loss: 0.148601\n",
      "Step 56200, Train Loss: 0.16158\n",
      "Step 56400, Train Loss: 0.158528\n",
      "Step 56600, Train Loss: 0.161489\n",
      "Step 56800, Train Loss: 0.167292\n",
      "Step 57000, Train Loss: 0.151855\n",
      "Step 57200, Train Loss: 0.154669\n",
      "Step 57400, Train Loss: 0.131386\n",
      "Step 57600, Train Loss: 0.146939\n",
      "Step 57800, Train Loss: 0.154697\n",
      "Step 58000, Train Loss: 0.158283\n",
      "Step 58200, Train Loss: 0.137715\n",
      "Step 58400, Train Loss: 0.146336\n",
      "Step 58600, Train Loss: 0.135482\n",
      "Step 58800, Train Loss: 0.134016\n",
      "Step 59000, Train Loss: 0.133181\n",
      "Step 59200, Train Loss: 0.134844\n",
      "Step 59400, Train Loss: 0.159403\n",
      "Step 59600, Train Loss: 0.146233\n",
      "Step 59800, Train Loss: 0.139994\n",
      "Step 60000, Train Loss: 0.146149\n",
      "Step 60200, Train Loss: 0.153092\n",
      "Step 60400, Train Loss: 0.134486\n",
      "Step 60600, Train Loss: 0.134994\n",
      "Step 60800, Train Loss: 0.160828\n",
      "Step 61000, Train Loss: 0.140655\n",
      "----End epoch 7, Val Loss: 0.138459\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_20/epoch7\\\\saved_model.pb'\n",
      "Step 61200, Train Loss: 0.147569\n",
      "Step 61400, Train Loss: 0.142255\n",
      "Step 61600, Train Loss: 0.148714\n",
      "Step 61800, Train Loss: 0.163026\n",
      "Step 62000, Train Loss: 0.152759\n",
      "Step 62200, Train Loss: 0.144719\n",
      "Step 62400, Train Loss: 0.148581\n",
      "Step 62600, Train Loss: 0.165996\n",
      "Step 62800, Train Loss: 0.14627\n",
      "Step 63000, Train Loss: 0.137572\n",
      "Step 63200, Train Loss: 0.139053\n",
      "Step 63400, Train Loss: 0.147823\n",
      "Step 63600, Train Loss: 0.149751\n",
      "Step 63800, Train Loss: 0.14712\n",
      "Step 64000, Train Loss: 0.136849\n",
      "Step 64200, Train Loss: 0.143802\n",
      "Step 64400, Train Loss: 0.137388\n",
      "Step 64600, Train Loss: 0.164021\n",
      "Step 64800, Train Loss: 0.155511\n",
      "Step 65000, Train Loss: 0.133008\n",
      "Step 65200, Train Loss: 0.162295\n",
      "Step 65400, Train Loss: 0.14867\n",
      "Step 65600, Train Loss: 0.157568\n",
      "Step 65800, Train Loss: 0.142643\n",
      "Step 66000, Train Loss: 0.155294\n",
      "Step 66200, Train Loss: 0.139183\n",
      "Step 66400, Train Loss: 0.142705\n",
      "Step 66600, Train Loss: 0.148304\n",
      "Step 66800, Train Loss: 0.144543\n",
      "Step 67000, Train Loss: 0.131831\n",
      "Step 67200, Train Loss: 0.145799\n",
      "Step 67400, Train Loss: 0.135431\n",
      "Step 67600, Train Loss: 0.156955\n",
      "Step 67800, Train Loss: 0.131101\n",
      "Step 68000, Train Loss: 0.142535\n",
      "Step 68200, Train Loss: 0.162673\n",
      "Step 68400, Train Loss: 0.134052\n",
      "Step 68600, Train Loss: 0.137869\n",
      "----End epoch 8, Val Loss: 0.147314\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_20/epoch8\\\\saved_model.pb'\n",
      "   21 | 56m15s |   -0.13846 |      32.0000 |    0.7500 |           8.0000 |       1.0000 |    0.1000 |       1.0000 |          0.0001 |    81.0853 |      0.0000 |     1.0000 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.73393214210225599, 'optimizer': 'adam', 'batch_size': 112, 'dropout': 0.30966400838548147, 'init_stdev': 0.49741360090872427, 'num_epochs': 20, 'n_hidden': 123, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.017056769733664691, 'embedding_size': 21}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 286.905\n",
      "Step 200, Train Loss: 0.140912\n",
      "Step 400, Train Loss: 0.140667\n",
      "Step 600, Train Loss: 0.140786\n",
      "Step 800, Train Loss: 0.119716\n",
      "Step 1000, Train Loss: 0.135844\n",
      "Step 1200, Train Loss: 0.144651\n",
      "Step 1400, Train Loss: 0.132597\n",
      "Step 1600, Train Loss: 0.154871\n",
      "Step 1800, Train Loss: 0.450257\n",
      "Step 2000, Train Loss: 0.563649\n",
      "----End epoch 0, Val Loss: 0.219404\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_21/epoch0\\\\saved_model.pb'\n",
      "Step 2200, Train Loss: 0.241947\n",
      "Step 2400, Train Loss: 0.46108\n",
      "Step 2600, Train Loss: 0.375502\n",
      "Step 2800, Train Loss: 0.37466\n",
      "Step 3000, Train Loss: 0.4508\n",
      "Step 3200, Train Loss: 0.396469\n",
      "Step 3400, Train Loss: 0.428204\n",
      "Step 3600, Train Loss: 0.388993\n",
      "Step 3800, Train Loss: 0.401971\n",
      "Step 4000, Train Loss: 0.411636\n",
      "Step 4200, Train Loss: 0.406075\n",
      "----End epoch 1, Val Loss: 0.406974\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_21/epoch1\\\\saved_model.pb'\n",
      "Step 4400, Train Loss: 0.412821\n",
      "Step 4600, Train Loss: 0.40268\n",
      "Step 4800, Train Loss: 0.412061\n",
      "Step 5000, Train Loss: 0.397941\n",
      "Step 5200, Train Loss: 0.408012\n",
      "Step 5400, Train Loss: 0.41616\n",
      "Step 5600, Train Loss: 0.383082\n",
      "Step 5800, Train Loss: 0.40807\n",
      "Step 6000, Train Loss: 0.397588\n",
      "Step 6200, Train Loss: 0.39469\n",
      "Step 6400, Train Loss: 0.413999\n",
      "----End epoch 2, Val Loss: 0.412486\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_21/epoch2\\\\saved_model.pb'\n",
      "Step 6600, Train Loss: 0.40678\n",
      "Step 6800, Train Loss: 0.411064\n",
      "Step 7000, Train Loss: 0.407212\n",
      "Step 7200, Train Loss: 0.401216\n",
      "Step 7400, Train Loss: 0.385065\n",
      "Step 7600, Train Loss: 0.404507\n",
      "Step 7800, Train Loss: 0.402653\n",
      "Step 8000, Train Loss: 0.395315\n",
      "Step 8200, Train Loss: 0.406512\n",
      "Step 8400, Train Loss: 0.426539\n",
      "Step 8600, Train Loss: 0.394292\n",
      "----End epoch 3, Val Loss: 0.411075\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_21/epoch3\\\\saved_model.pb'\n",
      "   22 | 20m00s |   -0.21940 |     112.1134 |    0.3097 |          21.8429 |       0.4974 |    0.0171 |       0.3672 |          0.7339 |   123.0169 |      0.3044 |     0.0771 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.53043930618773871, 'optimizer': 'adam', 'batch_size': 93, 'dropout': 0.26245855626961906, 'init_stdev': 0.70464303890278779, 'num_epochs': 20, 'n_hidden': 247, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.018551306901287545, 'embedding_size': 8}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 575.017\n",
      "Step 200, Train Loss: 0.14485\n",
      "Step 400, Train Loss: 0.145495\n",
      "Step 600, Train Loss: 0.148863\n",
      "Step 800, Train Loss: 0.153266\n",
      "Step 1000, Train Loss: 0.148372\n",
      "Step 1200, Train Loss: 0.150456\n",
      "Step 1400, Train Loss: 0.14526\n",
      "Step 1600, Train Loss: 0.142925\n",
      "Step 1800, Train Loss: 0.68106\n",
      "Step 2000, Train Loss: 1.10211\n",
      "Step 2200, Train Loss: 0.269405\n",
      "Step 2400, Train Loss: 0.882068\n",
      "Step 2600, Train Loss: 0.545344\n",
      "----End epoch 0, Val Loss: 0.521221\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_22/epoch0\\\\saved_model.pb'\n",
      "Step 2800, Train Loss: 0.632048\n",
      "Step 3000, Train Loss: 0.743786\n",
      "Step 3200, Train Loss: 0.685031\n",
      "Step 3400, Train Loss: 0.636566\n",
      "Step 3600, Train Loss: 0.643318\n",
      "Step 3800, Train Loss: 0.632127\n",
      "Step 4000, Train Loss: 0.599148\n",
      "Step 4200, Train Loss: 0.669407\n",
      "Step 4400, Train Loss: 0.64286\n",
      "Step 4600, Train Loss: 0.676708\n",
      "Step 4800, Train Loss: 0.61041\n",
      "Step 5000, Train Loss: 0.674503\n",
      "Step 5200, Train Loss: 0.693804\n",
      "----End epoch 1, Val Loss: 0.646536\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_22/epoch1\\\\saved_model.pb'\n",
      "Step 5400, Train Loss: 0.648527\n",
      "Step 5600, Train Loss: 0.666674\n",
      "Step 5800, Train Loss: 0.641863\n",
      "Step 6000, Train Loss: 0.689048\n",
      "Step 6200, Train Loss: 0.653439\n",
      "Step 6400, Train Loss: 0.667848\n",
      "Step 6600, Train Loss: 0.695725\n",
      "Step 6800, Train Loss: 0.634624\n",
      "Step 7000, Train Loss: 0.660118\n",
      "Step 7200, Train Loss: 0.66651\n",
      "Step 7400, Train Loss: 0.669971\n",
      "Step 7600, Train Loss: 0.680665\n",
      "Step 7800, Train Loss: 0.659576\n",
      "----End epoch 2, Val Loss: 0.633013\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_22/epoch2\\\\saved_model.pb'\n",
      "Step 8000, Train Loss: 0.680244\n",
      "Step 8200, Train Loss: 0.660955\n",
      "Step 8400, Train Loss: 0.680721\n",
      "Step 8600, Train Loss: 0.630759\n",
      "Step 8800, Train Loss: 0.679387\n",
      "Step 9000, Train Loss: 0.634369\n",
      "Step 9200, Train Loss: 0.658908\n",
      "Step 9400, Train Loss: 0.676475\n",
      "Step 9600, Train Loss: 0.669746\n",
      "Step 9800, Train Loss: 0.647781\n",
      "Step 10000, Train Loss: 0.635789\n",
      "Step 10200, Train Loss: 0.662413\n",
      "Step 10400, Train Loss: 0.631967\n",
      "----End epoch 3, Val Loss: 0.690403\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_22/epoch3\\\\saved_model.pb'\n",
      "   23 | 37m15s |   -0.52122 |      93.1610 |    0.2625 |           8.5977 |       0.7046 |    0.0186 |       0.9409 |          0.5304 |   247.2581 |      0.4097 |     0.0935 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 1.0, 'optimizer': 'adam', 'batch_size': 198, 'dropout': 0.75, 'init_stdev': 1.0, 'num_epochs': 20, 'n_hidden': 250, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.10000000000000001, 'embedding_size': 79}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 15608.2\n",
      "Step 200, Train Loss: 0.143188\n",
      "Step 400, Train Loss: 0.141887\n",
      "Step 600, Train Loss: 0.141182\n",
      "Step 800, Train Loss: 0.135531\n",
      "Step 1000, Train Loss: 0.144425\n",
      "Step 1200, Train Loss: 0.147207\n",
      "----End epoch 0, Val Loss: 0.212199\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_23/epoch0\\\\saved_model.pb'\n",
      "Step 1400, Train Loss: 0.224625\n",
      "Step 1600, Train Loss: 0.240152\n",
      "Step 1800, Train Loss: 0.276113\n",
      "Step 2000, Train Loss: 65.0511\n",
      "Step 2200, Train Loss: 1.15353\n",
      "Step 2400, Train Loss: 6.49337\n",
      "----End epoch 1, Val Loss: 10.0732\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_23/epoch1\\\\saved_model.pb'\n",
      "   24 | 19m33s |   -0.21220 |     198.1107 |    0.7500 |          79.6767 |       1.0000 |    0.1000 |       1.0000 |          1.0000 |   250.0000 |      0.0000 |     1.0000 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 1.0, 'optimizer': 'adam', 'batch_size': 192, 'dropout': 0.75, 'init_stdev': 0.0001, 'num_epochs': 20, 'n_hidden': 156, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.10000000000000001, 'embedding_size': 8}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 4711.35\n",
      "Step 200, Train Loss: 0.138498\n",
      "Step 400, Train Loss: 0.137869\n",
      "Step 600, Train Loss: 0.147877\n",
      "Step 800, Train Loss: 0.145175\n",
      "Step 1000, Train Loss: 0.146147\n",
      "Step 1200, Train Loss: 0.142552\n",
      "----End epoch 0, Val Loss: 0.139836\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_24/epoch0\\\\saved_model.pb'\n",
      "Step 1400, Train Loss: 0.147193\n",
      "Step 1600, Train Loss: 0.146023\n",
      "Step 1800, Train Loss: 0.187578\n",
      "Step 2000, Train Loss: 20.458\n",
      "Step 2200, Train Loss: 0.214117\n",
      "Step 2400, Train Loss: 1.87722\n",
      "----End epoch 1, Val Loss: 5.3095\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_24/epoch1\\\\saved_model.pb'\n",
      "   25 | 10m00s |   -0.13984 |     192.3140 |    0.7500 |           8.0000 |       0.0001 |    0.1000 |       1.0000 |          1.0000 |   156.3921 |      0.0000 |     1.0000 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 1.0, 'optimizer': 'adam', 'batch_size': 32, 'dropout': 0.75, 'init_stdev': 0.0001, 'num_epochs': 20, 'n_hidden': 25, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.0, 'embedding_size': 38}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 0.357371\n",
      "Step 200, Train Loss: 0.186269\n",
      "Step 400, Train Loss: 0.168992\n",
      "Step 600, Train Loss: 0.140423\n",
      "Step 800, Train Loss: 0.151051\n",
      "Step 1000, Train Loss: 0.1634\n",
      "Step 1200, Train Loss: 0.202019\n",
      "Step 1400, Train Loss: 0.900456\n",
      "Step 1600, Train Loss: 0.154596\n",
      "Step 1800, Train Loss: 0.332965\n",
      "Step 2000, Train Loss: 0.149535\n",
      "Step 2200, Train Loss: 0.153736\n",
      "Step 2400, Train Loss: 0.140176\n",
      "Step 2600, Train Loss: 0.134264\n",
      "Step 2800, Train Loss: 0.190536\n",
      "Step 3000, Train Loss: 0.155209\n",
      "Step 3200, Train Loss: 0.147009\n",
      "Step 3400, Train Loss: 0.141139\n",
      "Step 3600, Train Loss: 0.159112\n",
      "Step 3800, Train Loss: 0.159431\n",
      "Step 4000, Train Loss: 0.162388\n",
      "Step 4200, Train Loss: 0.165936\n",
      "Step 4400, Train Loss: 0.156469\n",
      "Step 4600, Train Loss: 0.160698\n",
      "Step 4800, Train Loss: 0.140462\n",
      "Step 5000, Train Loss: 0.154642\n",
      "Step 5200, Train Loss: 0.16371\n",
      "Step 5400, Train Loss: 0.205817\n",
      "Step 5600, Train Loss: 0.175135\n",
      "Step 5800, Train Loss: 0.13747\n",
      "Step 6000, Train Loss: 0.173734\n",
      "Step 6200, Train Loss: 0.140883\n",
      "Step 6400, Train Loss: 0.177638\n",
      "Step 6600, Train Loss: 0.530818\n",
      "Step 6800, Train Loss: 0.15462\n",
      "Step 7000, Train Loss: 0.127728\n",
      "Step 7200, Train Loss: 0.137336\n",
      "Step 7400, Train Loss: 0.133068\n",
      "Step 7600, Train Loss: 0.159089\n",
      "----End epoch 0, Val Loss: 0.154845\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_25/epoch0\\\\saved_model.pb'\n",
      "Step 7800, Train Loss: 0.147672\n",
      "Step 8000, Train Loss: 0.139674\n",
      "Step 8200, Train Loss: 0.149319\n",
      "Step 8400, Train Loss: 0.153298\n",
      "Step 8600, Train Loss: 0.148637\n",
      "Step 8800, Train Loss: 0.169626\n",
      "Step 9000, Train Loss: 0.133551\n",
      "Step 9200, Train Loss: 0.145532\n",
      "Step 9400, Train Loss: 0.136402\n",
      "Step 9600, Train Loss: 0.135445\n",
      "Step 9800, Train Loss: 0.168314\n",
      "Step 10000, Train Loss: 0.134696\n",
      "Step 10200, Train Loss: 0.135715\n",
      "Step 10400, Train Loss: 0.142961\n",
      "Step 10600, Train Loss: 0.156353\n",
      "Step 10800, Train Loss: 0.173189\n",
      "Step 11000, Train Loss: 0.167461\n",
      "Step 11200, Train Loss: 0.181959\n",
      "Step 11400, Train Loss: 0.130276\n",
      "Step 11600, Train Loss: 0.170854\n",
      "Step 11800, Train Loss: 0.148415\n",
      "Step 12000, Train Loss: 0.144574\n",
      "Step 12200, Train Loss: 0.134262\n",
      "Step 12400, Train Loss: 0.151374\n",
      "Step 12600, Train Loss: 0.168498\n",
      "Step 12800, Train Loss: 0.140611\n",
      "Step 13000, Train Loss: 0.343766\n",
      "Step 13200, Train Loss: 0.157479\n",
      "Step 13400, Train Loss: 0.157654\n",
      "Step 13600, Train Loss: 0.148496\n",
      "Step 13800, Train Loss: 0.165956\n",
      "Step 14000, Train Loss: 0.152526\n",
      "Step 14200, Train Loss: 0.135653\n",
      "Step 14400, Train Loss: 0.151373\n",
      "Step 14600, Train Loss: 0.155501\n",
      "Step 14800, Train Loss: 0.155785\n",
      "Step 15000, Train Loss: 0.153959\n",
      "Step 15200, Train Loss: 0.161564\n",
      "----End epoch 1, Val Loss: 0.154312\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_25/epoch1\\\\saved_model.pb'\n",
      "Step 15400, Train Loss: 0.135173\n",
      "Step 15600, Train Loss: 0.17262\n",
      "Step 15800, Train Loss: 0.956221\n",
      "Step 16000, Train Loss: 0.147764\n",
      "Step 16200, Train Loss: 0.172063\n",
      "Step 16400, Train Loss: 0.145875\n",
      "Step 16600, Train Loss: 0.140493\n",
      "Step 16800, Train Loss: 0.14178\n",
      "Step 17000, Train Loss: 0.146877\n",
      "Step 17200, Train Loss: 0.131263\n",
      "Step 17400, Train Loss: 0.146294\n",
      "Step 17600, Train Loss: 2.35383\n",
      "Step 17800, Train Loss: 4.87098\n",
      "Step 18000, Train Loss: 3.59133\n",
      "Step 18200, Train Loss: 0.170717\n",
      "Step 18400, Train Loss: 0.256227\n",
      "Step 18600, Train Loss: 0.165554\n",
      "Step 18800, Train Loss: 0.192359\n",
      "Step 19000, Train Loss: 0.185584\n",
      "Step 19200, Train Loss: 0.190156\n",
      "Step 19400, Train Loss: 0.115212\n",
      "Step 19600, Train Loss: 0.145266\n",
      "Step 19800, Train Loss: 0.180788\n",
      "Step 20000, Train Loss: 0.243333\n",
      "Step 20200, Train Loss: 2.92053\n",
      "Step 20400, Train Loss: 1.66551\n",
      "Step 20600, Train Loss: 0.202838\n",
      "Step 20800, Train Loss: 0.185253\n",
      "Step 21000, Train Loss: 0.26084\n",
      "Step 21200, Train Loss: 1.09748\n",
      "Step 21400, Train Loss: 3.90856\n",
      "Step 21600, Train Loss: 0.157584\n",
      "Step 21800, Train Loss: 0.122226\n",
      "Step 22000, Train Loss: 2.19993\n",
      "Step 22200, Train Loss: 2.08526\n",
      "Step 22400, Train Loss: 3.02227\n",
      "Step 22600, Train Loss: 0.538535\n",
      "Step 22800, Train Loss: 0.2583\n",
      "----End epoch 2, Val Loss: 0.600648\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_25/epoch2\\\\saved_model.pb'\n",
      "Step 23000, Train Loss: 1.20027\n",
      "Step 23200, Train Loss: 4.68151\n",
      "Step 23400, Train Loss: 7.04871\n",
      "Step 23600, Train Loss: 20.0996\n",
      "Step 23800, Train Loss: 1.19247\n",
      "Step 24000, Train Loss: 10.1384\n",
      "Step 24200, Train Loss: 0.177685\n",
      "Step 24400, Train Loss: 1.98789\n",
      "Step 24600, Train Loss: 7.988\n",
      "Step 24800, Train Loss: 8.0532\n",
      "Step 25000, Train Loss: 0.18468\n",
      "Step 25200, Train Loss: 0.186842\n",
      "Step 25400, Train Loss: 0.167902\n",
      "Step 25600, Train Loss: 4.31491\n",
      "Step 25800, Train Loss: 0.244621\n",
      "Step 26000, Train Loss: 0.794003\n",
      "Step 26200, Train Loss: 1.06956\n",
      "Step 26400, Train Loss: 0.403915\n",
      "Step 26600, Train Loss: 0.14285\n",
      "Step 26800, Train Loss: 1.81879\n",
      "Step 27000, Train Loss: 0.146446\n",
      "Step 27200, Train Loss: 0.188474\n",
      "Step 27400, Train Loss: 1.49121\n",
      "Step 27600, Train Loss: 0.196646\n",
      "Step 27800, Train Loss: 0.18495\n",
      "Step 28000, Train Loss: 5.8128\n",
      "Step 28200, Train Loss: 5.69581\n",
      "Step 28400, Train Loss: 0.150422\n",
      "Step 28600, Train Loss: 0.157728\n",
      "Step 28800, Train Loss: 0.229199\n",
      "Step 29000, Train Loss: 1.16578\n",
      "Step 29200, Train Loss: 1.99283\n",
      "Step 29400, Train Loss: 0.17052\n",
      "Step 29600, Train Loss: 6.35302\n",
      "Step 29800, Train Loss: 0.191015\n",
      "Step 30000, Train Loss: 1.69992\n",
      "Step 30200, Train Loss: 0.462843\n",
      "Step 30400, Train Loss: 1.82061\n",
      "----End epoch 3, Val Loss: 0.522618\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_25/epoch3\\\\saved_model.pb'\n",
      "   26 | 14m15s |   -0.15431 |      32.0000 |    0.7500 |          38.6180 |       0.0001 |    0.0000 |       0.0000 |          1.0000 |    25.0000 |      1.0000 |     1.0000 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.0001, 'optimizer': 'adam', 'batch_size': 256, 'dropout': 0.75, 'init_stdev': 0.0001, 'num_epochs': 20, 'n_hidden': 188, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.0, 'embedding_size': 8}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 0.924794\n",
      "Step 200, Train Loss: 0.909671\n",
      "Step 400, Train Loss: 0.88549\n",
      "Step 600, Train Loss: 0.846706\n",
      "Step 800, Train Loss: 0.790097\n",
      "----End epoch 0, Val Loss: 0.747418\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_26/epoch0\\\\saved_model.pb'\n",
      "Step 1000, Train Loss: 0.736387\n",
      "Step 1200, Train Loss: 0.672721\n",
      "Step 1400, Train Loss: 0.612226\n",
      "Step 1600, Train Loss: 0.565654\n",
      "Step 1800, Train Loss: 0.502696\n",
      "----End epoch 1, Val Loss: 0.460496\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_26/epoch1\\\\saved_model.pb'\n",
      "Step 2000, Train Loss: 0.449528\n",
      "Step 2200, Train Loss: 0.420581\n",
      "Step 2400, Train Loss: 0.374644\n",
      "Step 2600, Train Loss: 0.365238\n",
      "Step 2800, Train Loss: 0.335934\n",
      "----End epoch 2, Val Loss: 0.326673\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_26/epoch2\\\\saved_model.pb'\n",
      "Step 3000, Train Loss: 0.318484\n",
      "Step 3200, Train Loss: 0.289508\n",
      "Step 3400, Train Loss: 0.273821\n",
      "Step 3600, Train Loss: 0.259762\n",
      "Step 3800, Train Loss: 0.253489\n",
      "----End epoch 3, Val Loss: 0.26157\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_26/epoch3\\\\saved_model.pb'\n",
      "Step 4000, Train Loss: 0.233635\n",
      "Step 4200, Train Loss: 0.225593\n",
      "Step 4400, Train Loss: 0.222695\n",
      "Step 4600, Train Loss: 0.215438\n",
      "----End epoch 4, Val Loss: 0.206852\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_26/epoch4\\\\saved_model.pb'\n",
      "Step 4800, Train Loss: 0.214714\n",
      "Step 5000, Train Loss: 0.203088\n",
      "Step 5200, Train Loss: 0.190565\n",
      "Step 5400, Train Loss: 0.195469\n",
      "Step 5600, Train Loss: 0.186771\n",
      "----End epoch 5, Val Loss: 0.185819\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_26/epoch5\\\\saved_model.pb'\n",
      "Step 5800, Train Loss: 0.181886\n",
      "Step 6000, Train Loss: 0.181074\n",
      "Step 6200, Train Loss: 0.180685\n",
      "Step 6400, Train Loss: 0.177649\n",
      "Step 6600, Train Loss: 0.172092\n",
      "----End epoch 6, Val Loss: 0.170809\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_26/epoch6\\\\saved_model.pb'\n",
      "Step 6800, Train Loss: 0.16402\n",
      "Step 7000, Train Loss: 0.163527\n",
      "Step 7200, Train Loss: 0.163727\n",
      "Step 7400, Train Loss: 0.166553\n",
      "Step 7600, Train Loss: 0.156423\n",
      "----End epoch 7, Val Loss: 0.166192\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_26/epoch7\\\\saved_model.pb'\n",
      "Step 7800, Train Loss: 0.162187\n",
      "Step 8000, Train Loss: 0.153732\n",
      "Step 8200, Train Loss: 0.161305\n",
      "Step 8400, Train Loss: 0.158215\n",
      "----End epoch 8, Val Loss: 0.153129\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_26/epoch8\\\\saved_model.pb'\n",
      "   27 | 50m04s |   -0.15313 |     256.0000 |    0.7500 |           8.0000 |       0.0001 |    0.0000 |       0.0000 |          0.0001 |   188.4059 |      1.0000 |     0.0000 | \n",
      "{'embedding_activation': 'linear', 'layer_norm': False, 'n_input': 48, 'learning_rate': 0.5086469839916431, 'optimizer': 'adam', 'batch_size': 102, 'dropout': 0.36670331292930014, 'init_stdev': 0.69911755079262849, 'num_epochs': 20, 'n_hidden': 246, 'seq_length': 18, 'n_output': 24, 'rnn_type': 'lstm2', 'l2': 0.058166172253878823, 'embedding_size': 64}\n",
      "Variable w_alphas:0 will be regularized\n",
      "Variable w_out:0 will be regularized\n",
      "Variable w_emb:0 will be regularized\n",
      "Variable rnn/lstm_cell/kernel:0 will be regularized\n",
      "INFO:tensorflow:Summary name w_alphas:0 is illegal; using w_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name w_out:0 is illegal; using w_out_0 instead.\n",
      "INFO:tensorflow:Summary name w_emb:0 is illegal; using w_emb_0 instead.\n",
      "INFO:tensorflow:Summary name b_out:0 is illegal; using b_out_0 instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0 is illegal; using b_alphas_0 instead.\n",
      "INFO:tensorflow:Summary name b_emb:0 is illegal; using b_emb_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0 is illegal; using rnn/lstm_cell/kernel_0 instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0 is illegal; using rnn/lstm_cell/bias_0 instead.\n",
      "INFO:tensorflow:Summary name w_alphas:0/gradient is illegal; using w_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_out:0/gradient is illegal; using w_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name w_emb:0/gradient is illegal; using w_emb_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_out:0/gradient is illegal; using b_out_0/gradient instead.\n",
      "INFO:tensorflow:Summary name b_alphas:0/gradient is illegal; using b_alphas_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/kernel:0/gradient is illegal; using rnn/lstm_cell/kernel_0/gradient instead.\n",
      "INFO:tensorflow:Summary name rnn/lstm_cell/bias:0/gradient is illegal; using rnn/lstm_cell/bias_0/gradient instead.\n",
      "Step 1, Train Loss: 2035.98\n",
      "Step 200, Train Loss: 0.138241\n",
      "Step 400, Train Loss: 0.143061\n",
      "Step 600, Train Loss: 0.143085\n",
      "Step 800, Train Loss: 0.142433\n",
      "Step 1000, Train Loss: 0.142791\n",
      "Step 1200, Train Loss: 0.150738\n",
      "Step 1400, Train Loss: 0.151654\n",
      "Step 1600, Train Loss: 0.157421\n",
      "Step 1800, Train Loss: 2.30664\n",
      "Step 2000, Train Loss: 3.39636\n",
      "Step 2200, Train Loss: 0.617831\n",
      "----End epoch 0, Val Loss: 2.50664\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'protobuf_models/BO_Attention_RNN_Adam_27/epoch0\\\\saved_model.pb'\n",
      "Step 2400, Train Loss: 2.57197\n",
      "Step 2600, Train Loss: 1.67436\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ee4edeb7ca5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mrnnBO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Final Results'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnnBO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'max_val'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[1;31m# Append most recently generated values to X and Y arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobserve_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpwarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mobserve_point\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[1;31m# measure the target function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_observation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a8b6591dc80d>\u001b[0m in \u001b[0;36mmodel_evaluate\u001b[0;34m(n_hidden, init_stdev, learning_rate, optimizer, rnn_type, batch_size, embedding_size, dropout, l2, layer_norm)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdropout_keep_prob\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mbest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout_keep_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-57e8c3077a15>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(name_model, parameters, x, y, dropout_keep_prob, loss, init, optimizer, ds)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[1;31m# Run optimization op (backprop)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout_keep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dropout'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[1;31m# Compute train loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_iter = 30\n",
    "init_points = 5\n",
    "\n",
    "\n",
    "rnnBO = BayesianOptimization(model_evaluate, {'n_hidden': (25, 250),\n",
    "                                              'init_stdev': (0.0001, 1),\n",
    "                                              'learning_rate': (0.0001, 1),\n",
    "                                              'optimizer': (0,1), # We could try to bin\n",
    "                                              #'optimizer': ['adam', 'sgd', 'adadelta', 'adagrad'],\n",
    "                                              'rnn_type': (0,1), # We could try to bin\n",
    "                                              #'rnn_type': ['lstm', 'lstm2', 'gru', 'lstm_normalized'],\n",
    "                                              'batch_size': (32,256),\n",
    "                                              #'batch_size': [32, 64, 128, 256],\n",
    "                                              'embedding_size': (8, 128),\n",
    "                                              'dropout': (0, 0.75),\n",
    "                                              'l2': (0, 0.1),\n",
    "                                              'layer_norm': (0,1) # We could try to bin\n",
    "                                              #'layer_norm': [False, True]\n",
    "                                              \n",
    "                                            })\n",
    "\n",
    "                                                            \n",
    "rnnBO.maximize(init_points=init_points, n_iter=num_iter)\n",
    "print('Final Results')\n",
    "print(rnnBO.res['max']['max_val'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['max', 'all'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnnBO.res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_params': {'batch_size': 32.647807387428223,\n",
       "  'dropout': 0.75,\n",
       "  'embedding_size': 127.95092535699872,\n",
       "  'init_stdev': 0.0001,\n",
       "  'l2': 0.10000000000000001,\n",
       "  'layer_norm': 1.0,\n",
       "  'learning_rate': 1.0,\n",
       "  'n_hidden': 170.41140615571859,\n",
       "  'optimizer': 0.91583900091641623,\n",
       "  'rnn_type': 1.0},\n",
       " 'max_val': 8.509251594543457}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnnBO.res['max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0844449,\n",
       " 0.044632778,\n",
       " 8.3452883,\n",
       " 8.0845671,\n",
       " 8.2561235,\n",
       " 0.038058873,\n",
       " 1.8988473,\n",
       " 0.15590379,\n",
       " 1.8718715,\n",
       " 8.2232189,\n",
       " 8.5092516,\n",
       " 0.21960598,\n",
       " 5.9320645,\n",
       " 0.61612213,\n",
       " 0.083908357,\n",
       " 1.4520855,\n",
       " 0.19132216,\n",
       " 0.23011115,\n",
       " 2.28809,\n",
       " 6.521883,\n",
       " 2.8740845,\n",
       " 1.5333037,\n",
       " 0.13123024,\n",
       " 3.4975901,\n",
       " 0.16002724,\n",
       " 5.2910728,\n",
       " 2.9744067,\n",
       " 0.90664864,\n",
       " 4.2031875,\n",
       " 5.4279366]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnnBO.res['all']['values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32.0,\n",
       " 'dropout': 0.0,\n",
       " 'embedding_size': 128.0,\n",
       " 'init_stdev': 0.0001,\n",
       " 'l2': 0.0,\n",
       " 'layer_norm': 0.0,\n",
       " 'learning_rate': 0.0001,\n",
       " 'n_hidden': 168.96377943115036,\n",
       " 'optimizer': 1.0,\n",
       " 'rnn_type': 0.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnnBO.res['all']['params'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X',\n",
       " 'Y',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_acqkw',\n",
       " '_observe_point',\n",
       " 'bounds',\n",
       " 'dim',\n",
       " 'explore',\n",
       " 'f',\n",
       " 'gp',\n",
       " 'i',\n",
       " 'init',\n",
       " 'init_points',\n",
       " 'initialize',\n",
       " 'initialize_df',\n",
       " 'initialized',\n",
       " 'keys',\n",
       " 'maximize',\n",
       " 'pbounds',\n",
       " 'plog',\n",
       " 'points_to_csv',\n",
       " 'random_state',\n",
       " 'res',\n",
       " 'set_bounds',\n",
       " 'space',\n",
       " 'util',\n",
       " 'verbose',\n",
       " 'x_init',\n",
       " 'y_init']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(rnnBO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "BO_Attention_RNN_2\n"
     ]
    }
   ],
   "source": [
    "variable_global = 3\n",
    "def test():\n",
    "    global num_model\n",
    "    print(num_model)\n",
    "    name_model = name_model_base + str(num_model)\n",
    "    print(name_model)\n",
    "    num_model += 1\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
